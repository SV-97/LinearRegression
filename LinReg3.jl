import Random
Random.seed!(0)

using Plots

"Sum from k=`from` to `to` of `a(k)`"
Î£(from::Integer, to::Integer, a::Function, zero = 0) = mapreduce(a, (+), from:to; init = zero)

"""Linear Regression
# Args:
    ğ°: Parameters
    Î¦(j, ğ±): Basis function of type (Int, Vector{T}) -> T
    ğ±: Input vector
"""
function y(ğ°::Vector{<:Number}, Î¦::(T where T <: Function), ğ±::Vector{<:Number})::(T where T <: Number)
    Î£(1, size(ğ°)[1], j->ğ°[j] * Î¦(j, ğ±))
end

"""Derivative of E_D with respect to ğ°â‚–
# Args:
    Î¦(k, ğ±â‚™): Basis function
    ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
    t: corresponding target values for each ğ±â‚™
    k: Index for ğ°â‚– in respect to which the derivative is taken
    ğ°: Parameters
"""
function âˆ‚E_Dâˆ‚w_k(Î¦, ğ—, t, ğ°, k)
    N = size(t)[1]
    - Î£(1, N, n->Î¦(k, ğ—[n]) * (t[n] - y(ğ°, Î¦, ğ—[n])))
end

"""Gradient descent iteration
# Args:
    Î¦: Basis Function
    ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
    t: corresponding target values for each ğ±â‚™
    ğ°: Parameters
    Î·: Learning rate
"""
function gd_iteration(Î¦, ğ—, t, ğ°::Vector{<:Number}, Î·)
    N = size(ğ°)[1]
    âˆ‡ğ° = zero(ğ°)
    for j = 1:N
        âˆ‚E_Dâˆ‚w_jk(k) = âˆ‚E_Dâˆ‚w_k(Î¦, ğ—, t, ğ°, k)
        âˆ‡ğ° += collect(map(âˆ‚E_Dâˆ‚w_jk, 1:N))
    end
    ğ° - Î· * âˆ‡ğ°
end

"""Find regression model using gradient descent
TODO Replace fixed-count iteration with a proper cancellation condition
# Args:
    Î¦: Basis Function
    ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
    t: corresponding target values for each ğ±â‚™
    Î·: learning rate with which to train
    M: Number of model parameters
    iters: Number of iterations
"""
function gd(Î¦, ğ—, t, Î·, M, iters)
    ğ° = randn(M)
    for i = 1:iters
        ğ° = gd_iteration(Î¦, ğ—, t, ğ°, Î· * 1/i)
        # println(ğ°)
        model(ğ±â‚™) = y(ğ°, Î¦, ğ±â‚™)
        println("y' = ", model.(ğ—))
    end
    ğ±->y(ğ°, Î¦, ğ±)
end

# optimal solution using a linear model for comparison

x_b = [1, 2, 3]
y_b = [1, 1, 2]

function fitline(x::Vector{<:Number}, y::Vector{<:Number})::Function
    n = size(x)[1]
    a = (sum(y) * sum(x.^2) - sum(x) * sum(x .* y)) / (n * sum(x.^2) - sum(x)^2) # t
    b = (n * sum(x .* y) - sum(x) * sum(y)) / (n * sum(x.^2) - sum(x)^2)# m
    x->b * x + a
end

optimal_linear_model = fitline(x_b, y_b)

# end of optimal solution

# a few different basis functions for testing
Î¦1(j, ğ±) =
    if j == 0
        1
    else
        ğ±[1]
end

Î¦2(j, ğ±) = ğ±[1]^j
Î¦3(j, ğ±) = sin(ğ±[1])
Ïƒ(a) = 1 / (1 + exp(-a))
function Î¦4(j, ğ±)
    Î¼ = 0.2
    s = 0.2
    Ïƒ((ğ±[1] - Î¼) / s)
end
# test

ğ— = [[1], [2], [3]]
t = [1, 1, 2]

model1 = gd(Î¦1, ğ—, t, 010.00, 2, 20000)

x = 1:0.1:5
p = scatter(map(x->x[1], ğ—), t, label = "training");
plot!(x, model1.(map(x->[x], x)), label = "prediction")
plot!(x, optimal_linear_model.(x), label = "optimal", line = :dot)
display(p)
readline()
