\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[german]{babel} % prefer english over german
\usepackage{multicol}
\usepackage{tikz}
\usetikzlibrary{angles,arrows,babel,calc,patterns,quotes}

\usepackage{graphicx}
\graphicspath{ {./img/} }

\usepackage{minted}
\usepackage{xcolor}
\usemintedstyle{manni}

\usepackage{eurosym}
\usepackage{amstext}

\usepackage{booktabs}

\usepackage{amssymb, amsmath, amsthm, amsfonts}

\usepackage{fontspec}

\usepackage{newunicodechar}

\newunicodechar{ğ°}{$\textbf{w}$}
\newunicodechar{ğ±}{$\textbf{x}$}
\newunicodechar{â‚™}{${}_n$}
\newunicodechar{ğ—}{$\textbf{X}$}
\newunicodechar{â‚–}{${}_k$}
\newunicodechar{âˆ‡}{$\nabla$}

%\usepackage{realhats}

\setmonofont[
  Mapping=tex-text,
  Scale=0.90,
  UprightFont=*-Regular,
  BoldFont=*-Bold,
  ]{Fira Code}
%\setmonofont[Mapping=tex-text, Scale=0.90,]{Droid Sans Mono}

\theoremstyle{plain} %Text ist Kursiv
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Korollar}

\theoremstyle{definition} %Text ist \"upright"
\newtheorem{remark}[theorem]{Bemerkung}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Beispiel}
\newtheorem{algo}[theorem]{Algorithm}
\newtheorem{problem}[theorem]{Problem}
\let\proof\undefined
\newtheorem{proof}[theorem]{Beweis}
\newtheorem{theo}[theorem]{Satz}
\newtheorem{anno}[theorem]{Anmerkung}
\newtheorem{solution}[theorem]{LÃ¶sung}

% Colors
\definecolor{bg}{rgb}{0.95,0.95,0.95}

\newcommand{\sfloor}[1]{\left\lfloor #1 \right\rfloor} % scaling floor function
\newcommand{\sceil}[1]{\left\lceil #1 \right\rceil} % scaling ceil function
\newcommand{\floor}[1]{\lfloor #1 \rfloor} % floor function
\newcommand{\ceil}[1]{\lceil #1 \rceil} % ceil function
\newcommand{\specialset}[1]{\rm I\!#1} % render sets like R and N fancy
\newcommand{\abs}[1]{\left\lVert#1\right\rVert} % Absolute value of #1
\newcommand{\unit}[1]{\hat{#1}} % unit vector

\title{ N-dimensionales Datenfitting mit linearer Regression  }

\author{
  Stefan Volz
}

\begin{document}

\begin{abstract}
  In vielen Anwendungen ist es nÃ¶tig/vorteilhaft aus Messdaten ein Mathematisches Modell zu entwickeln, welches mÃ¶glichst Messungenauigkeiten ausgleicht bzw. Vorhersagen zulÃ¤sst. Ziel der Arbeit ist die Implementierung von linearer Regression als Funktion hÃ¶herer Ordnung, welche mittels Gradientenabstieg eine Fehlerminimierung des Modells im Bezug auf gegebene Messdaten durchfÃ¼hrt. Die Implementierung erfolgt in Julia.
\end{abstract}

\maketitle
\section{Konventionen und Generelles}
\subsection{Wahl der Programmiersprache und AbhÃ¤ngigkeiten}
Die Implementierung erfolgt in Julia\footnote{\url{https://julialang.org/}}. Julia ist eine hochperformante, stark und dynamisch typisierte, Ã¼berwiegend imperative Programmiersprache mit Fokus auf wissenschaftlichem Rechnen; ist jedoch im Gegensatz zu z.B. MATLAB als General Purpose Sprache zu verstehen. Die Arbeit benutzt Julia in Version 1.2.0. Die AbhÃ¤ngigkeiten beschrÃ¤nken sich auf das \texttt{Plots} Package\footnote{\url{https://docs.juliaplots.org/}}.

Die Wahl der Sprache fiel auf Julia, da es nativ eine sehr gute UnterstÃ¼tzung fÃ¼r Matrizen mitbringt was fÃ¼r die Implementierung als sehr vorteilhaft angesehen wurde. AuÃŸerdem erlaubt der gute Unicode-Support es, Identifier so zu wÃ¤hlen, dass diese nah an der Fachliteratur sind.

\subsection{Quellcode}
Beim Code wurde darauf geachtet, die Typannotationen\footnote{\url{https://docs.julialang.org/en/v1/manual/types/}} von Julia zu nutzen, da diese zum einfacheren VerstÃ¤ndnis des Codes beitragen und auÃŸerdem der Performance zutrÃ¤glich sind.
Identifier wurden grÃ¶ÃŸtenteils so gewÃ¤hlt, dass sie sich mit \cite{Bishop} decken - teils wurden auch Bezeichner aus \cite{Lippe} Ã¼bernommen.

\subsection{Text dieser Arbeit}
Im Text der Arbeit werden - in Anlehnung an \cite{Bishop} - folgende Konventionen genutzt:

\begin{tabular}{llc}
  \toprule
  Typ & Beschreibung & Beispiel \\
  \midrule
  vektorielle GrÃ¶ÃŸen & fettgedruckte Kleinbuchstaben & $\mathbf{w}$ \\
  einzelne Elemente eines Vektors & indizierte Kleinbuchstaben & $w_j$ \\
  Matrizen und Mengen & GroÃŸbuchstaben & $A$ \\
  Hyperparameter des Modells & griechische Kleinbuchstaben & $\gamma$ \\
  sonstige Parameter & lateinische Kleinbuchstaben & $x$ \\
  Code listings und Quellcode-Referenzen & monospace font & \mintinline{julia}|code| \\
\end{tabular}

Einzelne Indizes an Matrixen wie z.B. $A_j$ sind als Zeilenindizes zu verstehen, sodass $A_j$ die j-te Zeile von $A$ ist.
In einigen FÃ¤llen wurde zwecks Konsistenzwahrung mit \cite{Bishop} von diesen Konventionen abgewichen.

\subsection{Variablenbezeichner}


\begin{tabular}{cl}
  \toprule
  Bezeichner & Beschreibung\\
  \midrule
  $d$ & Dimension eines Eingabevektors\\
  $k$ & Dimension eines Zielwertsvektors\\
  $M$ & Anzahl der Modellparameter\\
  $N$ & Anzahl der TrainingsdatensÃ¤tze\\
  $X$ & Trainingseingabematrix\\
  $T$ & Trainingszielmatrix\\
  $\mathbf{w}$ & Modellparameter\\
\end{tabular}


\section{Grundlegende Implementierung}
\subsection{Problemformulierung}
Seien $d,k,M,N \in \mathbb{N}$ mit Messdaten $X \in \mathbb{R}^{d \times N}$ und zugehÃ¶rigen Zielwerten $T \in \mathbb{R}^{k \times N}$ gegeben. Gesucht werden die Parameter $\mathbf{w}$ eines Modells $y(\mathbf{w}, \mathbf{x})$ mit $y \in \mathbb{R}^M \times \mathbb{R}^d \rightarrow \mathbb{R}^{k}$ welche das Minimierungsproblem
$$
    \min_{\mathbf{w} \in \mathbb{R}^M}\sum_{i=1}^N E(y(\mathbf{w}, X_{i}), T_{i}),
$$
im Bezug auf eine Fehlerfunktion $E: \mathbb{R}^k \times \mathbb{R}^k \rightarrow \mathbb{R}$ lÃ¶sen.

Wir betrachten zunÃ¤chst nur Probleme fÃ¼r die $k=1$ gilt und bezeichnen daher die Zielwerte mit $\mathbf{t}$.

\subsection{Lineare Regression}
\subsubsection{Mathematische Grundlagen}
Bei linearer Regression handelt es sich um eine Methode des Ã¼berwachten Lernens.
\begin{definition}
  Lineare Regressions Modelle sind Modelle, welche sich im Bezug auf ihre Modellparameter linear verhalten\cite[S. 137f]{Bishop}. Sie stellen Funktionen der Form $y: \mathbb{R}^M \times \mathbb{R}^d \rightarrow \mathbb{R}^k, (\mathbf{w}, \mathbf{x}) \mapsto y(\mathbf{w}, \mathbf{x})$ dar. Die Anzahl der Modellparameter ist gegeben durch $M \in \mathbb{N}$, die Anzahl an EingangsgrÃ¶ÃŸen durch $d \in \mathbb{N}$ und die der ZielgrÃ¶ÃŸen durch $k \in \mathbb{N}$.
\end{definition}
\begin{anno}
  Dies bedeutet nicht, dass sie auch zwingend linear im Bezug auf die Eingangsvariablen sein mÃ¼ssen.
\end{anno}

Das einfachste lineare Regressions Modell ist eine Linearkombination der Eingangsvariablen 
$$
  y(\mathbf{w}, \mathbf{x}) = w_0 + w_1x_1 + w_2x_2 + \hdots + w_Dx_D,
$$
diese spiegeln jedoch oftmals nicht die zugrunde-liegende Verteilung der realen Messwerte wider, und limitieren ein Modell mit $d$ Eingangsvariablen auf $d+1$ Modellparameter. Daher werden Basisfunktionen eingefÃ¼hrt und Lineare Regressionsmodelle als Linearkombination dieser gebildet.
\begin{definition}
  Eine Funktion $\Phi_j: \mathbb{R}^d \rightarrow \mathbb{R}^k, \mathbf{x} \mapsto \Phi_j(\mathbf{x})$ bezeichnen wir als Basisfunktion.
\end{definition}
\begin{anno}
  Im Code werden Basisfunktionen als Funktionen $\Phi: \mathbb{N} \times \mathbb{R}^d \rightarrow \mathbb{R}^k, (j, \mathbf{x}) \mapsto \Phi(j, \mathbf{x})$ implementiert.
\end{anno}

Mit diesen Basisfunktionen ergibt sich als Modellgleichung
$$
  y(\mathbf{w}, \mathbf{x}) = w_0 + \sum_{j=1}^{M-1}w_j\Phi_j(\mathbf{x}),
$$
wobei der Parameter $w_0$ auch als Bias-Parameter bezeichnet wird, da er einen festen Offset der Daten ermÃ¶glicht. Im Code werden wir diesen Bias-Parameter als ``normalen'' Parameter betrachten und als kleinsten Index in $\mathbf{w}$ $1$ wÃ¤hlen. Ein EingangsvariablenunabhÃ¤ngiger Offset ist leicht durch eine angepasste Definition der Basisfunktion erreichbar:
\[ \Phi: (j, \mathbf{x}) \mapsto
 \left\{
  \begin{array}{ll}
    1,& j=1, \\
    \Phi_j(\mathbf{x}), & sonst. \\  
  \end{array}
\right. \]

Damit vereinfacht sich die Darstellung der Modellgleichung zu
\begin{align}
  y(\mathbf{w}, \mathbf{x}) = \sum_{j=1}^{M}w_j\Phi(j, \mathbf{x}), \label{y}
\end{align}

\subsubsection{Implementierung}
Auf Basis dieser Formulierungen kÃ¶nnen wir mit der Implementierung beginnen.
Hierzu definieren wir uns zunÃ¤chst eine Funktion \texttt{$\Sigma$} um alle im Code vorkommenden Summen zu abzudecken.

\begin{listing}[!ht]
    \begin{minted}[bgcolor=bg]{julia}
        "Sum from k=`from` to `to` of `a(k)`"
        Î£(from::Integer, to::Integer, a::Function, zero = 0) =
          mapreduce(a, (+), from:to; init = zero)
    \end{minted}
    \caption{Funktion \mintinline{julia}|Î£|}
\end{listing}

Die Funktion ist hierbei eine Implementierung von $\sum_{k=\text{from}}^\text{to}a(k)$. Bei \texttt{mapreduce} handelt es sich um eine eingebaute Funktion welche (hier) erst \texttt{a} Ã¼ber eine Sequenz mappt und anschlieÃŸend diese Sequenz mittels \texttt{(+)} reduziert/faltet. Dabei ist \texttt{(+)} der eingebaute Additionsoperator. Der optionale Parameter \texttt{zero} erlaubt es die Funktion auch fÃ¼r nicht-skalare Summen(bzw. jegliche Typen fÃ¼r die eine Implementierung zu \texttt{+} existiert) zu nutzen.

\begin{listing}[!ht]
    \begin{minted}[bgcolor=bg]{Julia}
        """Linear Regression
        # Args:
            ğ°: Parameters
            Î¦(j, ğ±): Basis function of type (Int, Vector{T}) -> T
            ğ±: Input vector
        """
        function y(
          ğ°::Vector{<:Number},
          Î¦::(T where T <: Function),
          ğ±::Vector{<:Number})::(T where T <: Number)
            Î£(1, size(ğ°)[1], j->ğ°[j] * Î¦(j, ğ±))
        end
    \end{minted}
    \caption{Funktion \mintinline{julia}|y|}
    \label{listing:y}
\end{listing}

Diese Implementierung der Funktion \texttt{y} passt 1:1 zur mathematischen Formulierung in Gleichung \ref{y}\footnote{Die in Listing \ref{listing:y} genutzte Schreibweise \mintinline{julia}|Vector{<:Number}| bedeutet \emph{Vektor eines Typen T, wobei T ein Subtyp des Abstrakten Typs Number ist}. Diese hat gegenÃ¼ber \mintinline{julia}|Vector{Number}| den Vorteil, dass sie gewisse Optimierungen ermÃ¶glicht.}.

\subsection{Die Fehlerfunktion}

Als nÃ¤chstes benÃ¶tigen wir eine MÃ¶glichkeit um den Fehler des Systems zu ermitteln - sodass wir diesen im nÃ¤chsten Schritt minimieren kÃ¶nnen. Die genutzte Fehlerfunktion ist die des quadratischen Fehlers. Nach \cite[S. 140f]{Bishop} ergibt sich die Fehlerfunktion
\begin{align}
    E_D := \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, \mathbf{x}))^2.
\end{align}

Mit dieser Definition kÃ¶nnen wir nun unser Minimierungsproblem wie folgt definieren:
$$
  \min_{\mathbf{w} \in \mathbb{R}^M} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, X_n))^2.
$$
Im nÃ¤chsten Schritt werden wir ein Verfahren implementieren, das diese Minimierung durchfÃ¼hrt.

\subsection{Gradientenabstiegsverfahren}

\subsubsection{Mathematische Grundlagen}

Das Gradientenabstiegsverfahren ist ein numerisches Verfahren mit dem sich allgemeine Optimierungsprobleme lÃ¶sen lassen. Beim Gradientenabstiegsverfahren bestimmen wir den Gradienten von $E_D$ im Bezug auf die Modellparameter $\mathbf{w}$ - diesen Gradienten bezeichnen wir mit $\nabla_\mathbf{w} E_D$. Hierzu bestimmen wir zunÃ¤chst die partielle Ableitungen von $E_D$ nach allen $w_k$ aus $\mathbf{w}$.
$$
  \frac{\partial E_D}{\partial \mathbf{w}_k} = \frac{\partial}{\partial \mathbf{w}_k} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, \mathbf{x}))^2 = - \sum_{n=1}^N \Phi(k, X_n) \cdot (\mathbf{t}_n - y(\mathbf{w}, \Phi, X_n))
$$
Hieraus folgt dann fÃ¼r den Gradienten:
$$
  \nabla_\mathbf{w} E_D
    = \left( \begin{array}{c}
      \frac{\partial E_D}{\partial \mathbf{w_1}}\\
      \vdots\\
      \frac{\partial E_D}{\partial \mathbf{w_M}}\\
      \end{array} \right)
    =: \left( \begin{array}{c}
      e_1\\
      \vdots\\
      e_M\\
      \end{array} \right).
$$

FÃ¼r die komponentenweise Berechnung dieses Gradienten ergibt sich nach \cite[S. 95f]{Lippe}
$$
  \frac{1}{M}ppuuuuuuuuuuuuuh
$$

Um diesen Gradienten zu implementieren, beginnen wir mit der Implementierung der partiellen Ableitung:

\begin{listing}[!ht]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Derivative of E_D with respect to ğ°â‚–
    # Args:
        Î¦(k, ğ±â‚™): Basis function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        k: Index for ğ°â‚– in respect to which the derivative is taken
        ğ°: Parameters
    """
    function âˆ‚E_Dâˆ‚w_k(Î¦, ğ—, t, ğ°, k)
        N = size(t)[1]
        - Î£(1, N, n->Î¦(k, ğ—[n]) * (t[n] - y(ğ°, Î¦, ğ—[n])))
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|âˆ‚E_Dâˆ‚w_k|}
  \label{listing:partial}
\end{listing}

\subsubsection{Einzeliteration des Gradientenabstiegs}

Hiermit kÃ¶nnen wir eine Iteration des Gradientenabstiegsalgorithmus wie folgt implementieren.

\begin{listing}[!ht]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Gradient descent iteration
    # Args:
        Î¦: Basis Function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        ğ°: Parameters
        Î·: Learning rate
    """
    function gd_iteration(Î¦, ğ—, t, ğ°::Vector{<:Number}, Î·)
        M = size(ğ°)[1]
        âˆ‡ğ° = zero(ğ°)
        for j = 1:M
            âˆ‚E_Dâˆ‚w_jk(k) = âˆ‚E_Dâˆ‚w_k(Î¦, ğ—, t, ğ°, k)
            âˆ‡ğ° += collect(map(âˆ‚E_Dâˆ‚w_jk, 1:M))
        end
        ğ° - Î· * âˆ‡ğ°
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gd_iteration|}
  \label{listing:gd_iteration}
\end{listing}

Innerhalb der Funktion iterieren wir Ã¼ber alle Indizes $j$, bilden die partielle Ableitung nach $\mathbf{w}_k$ und berechnen ihren Wert fÃ¼r alle Komponenten des Ergebnisvektors. Der Gradient ist dann die Summe all dieser Vektoren. In der letzten Zeile der Funktion machen wir einen ''Schritt'' in Richtung des Gradienten - steigen auf der Fehlerkurve also ab. Die Schrittweite wird hierbei durch den Hyperparameter $\eta$ gesteuert. Dieser als Lernrate bezeichnete Parameter steuert im Grunde genommen die Konvergenzgeschwindigkeits des Gradientenabstiegsverfahrens.

\subsubsection{Hauptfunktion}

Auf Basis dieser Funktion kÃ¶nnen wir nun den Rest des Algorithmus in der Funktion \mintinline{julia}|gd| umsetzen.

\begin{listing}[!ht]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Find regression model using gradient descent
    # Args:
        Î¦: Basis Function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        Î·: learning rate with which to train
        M: Number of model parameters
        iters: Number of iterations
    """
    function gd(Î¦, ğ—, t, Î·, M, iters)
        ğ° = randn(M)
        for i = 1:iters
            ğ° = gd_iteration(Î¦, ğ—, t, ğ°, Î·, âˆ‡ğ°)
        end
        ğ±->y(ğ°, Î¦, ğ±)
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gd|}
  \label{listing:gd}
\end{listing}

Diese Funktion initialisiert die Modellparameter zu Beginn mit einem Vektor aus normalverteilten Zufallszahlen\cite{Lippe} aus dem Intervall $[-1, 1]$. Dann ruft sie \mintinline{julia}|iters|-mal die Hilsfunktion \mintinline{julia}|gd_iteration| auf und updated die Parameter mit dem Ergebnis dieser Aufrufe. SchlieÃŸlich gibt sie das vollendete Modell als Closure\footnote{Eine Closure ist eine anonyme Funktion welche intern eine Referenz auf ihren Erstellungskontext hÃ¤lt. Hier wird sie eingesetzt um \mintinline{julia}|y| mit \mintinline{julia}|ğ°| und \mintinline{julia}|Î¦| partiell zu evaluieren.} zurÃ¼ck, was dem die Funktion Aufrufenden ermÃ¶glicht, Modellaussagen in AbhÃ¤ngigkeit eines Eingangsvektors zu erhalten.

\subsubsection{Abbruchkriterium}

Die Grundimplementierung wird mit einem einfachen Abbruchkriterium abgeschlossen. Hierbei wird zu jeder Iteration geprÃ¼ft, ob die Norm der Differenz der Parametervektoren von zwei aufeinanderfolgenden Iterationen kleiner als ein neuer Hyperparameter $\varepsilon$ ist - in Formeln ausgedrÃ¼ckt: es wird geprÃ¼ft ob $||\mathbf{w} - \mathbf{w}'||_2 < \varepsilon$ gilt.
AuÃŸerdem wird geprÃ¼ft ob einer der Parameter zu $\pm\infty$ divergiert (und das Verfahren somit ''fehlgeschlagen'') ist oder durch einen Rechenfehler ein \mintinline{julia}|NaN|\footnote{\emph{Not a Number} - spezieller Wert von IEEE floats} in $\mathbf{w}$ aufgetaucht ist. In all diesen FÃ¤llen wird der Algorithmus vorzeitig abgebrochen und das Modell zurÃ¼ckgegeben\footnote{Der Punkt im Funktionsaufruf in Listing \ref{listing:simplebreak} sorgt dafÃ¼r, dass die Funktion vektorisiert/\emph{pointwise} aufgerufen wird (siehe \url{https://docs.julialang.org/en/v1/manual/functions/}).}.

\begin{listing}[!ht]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Find regression model using gradient descent
    # Args:
        Î¦: Basis Function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        Î·: learning rate with which to train
        M: Number of model parameters
        iters: Number of iterations
        Îµ: Gradient descent stops once the difference
          between two iterations (ğ° and ğ°') is less than Îµ
    """
    function gd(Î¦, ğ—, t, Î·, M, iters, Îµ=10e-12)
        ğ° = randn(M)
        for i = 1:iters
            ğ°_old = ğ°
            ğ° = gd_iteration(Î¦, ğ—, t, ğ°, Î·, âˆ‡ğ°, Î³)
            if norm(ğ°_old - ğ°) < Îµ || any(isnan.(ğ°)) || any(isinf.(ğ°))
                break
            end
        end
        println(ğ°)
        ğ±->y(ğ°, Î¦, ğ±)
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gd| mit einfachem Abbruchkriterium}
  \label{listing:simplebreak}
\end{listing}

FÃ¼r den Parameter $\varepsilon$ wird eine arbitrÃ¤r gewÃ¤hlte Standartbelegung von $10\cdot10^{-12}$ gesetzt.

\section{Fortgeschrittene Features}
\subsection{Momentum Verfahren/Konjugierter Gradientenabstieg}
Das Momentum Verfahren ist eine Adaption des Gradientenabstiegs, welche die Konvergenzgeschwindigkeit erhÃ¶hen soll. Das Ziel ist es, auf flachen Bereichen der Fehlerkurve die Abstiegsgeschwindigkeit zu erhÃ¶hen und sie in steilen Passagen zu verringern. Das Verfahren lÃ¤sst sich als ein Ball der eine Kurve hinabrollt visualisieren - dieser verhÃ¤lt sich bei Ã„nderungen der Kurve mit einer gewissen TrÃ¤gheit.
Um eine solche TrÃ¤gheit zu realisieren wird ein Momentum-Term hinzugefÃ¼gt. Dieser Term ist das Produkt des Gradienten der vorhergehenden Iteration und eines neuen Hyperparameters $\gamma \in [0,1)$ - dem TrÃ¤gheitsfaktor. Der Gradient $\nabla_\mathbf{w}\hat{E_D}$ in jeder Iteration ergibt sich dann aus dem eigentlichen Gradienten dieser Iteration $\nabla_\mathbf{w} E_D'$ sowie dem der vorhergehenden Iteration $\nabla_\mathbf{w} E_D$ multipliziert mit dem Momentum-Faktor $\gamma$.
$$
  \nabla_\mathbf{w} \hat{E}_D = \nabla_\mathbf{w} E_D' + \gamma \nabla_\mathbf{w} E_D
$$
Zur Implementierung mÃ¼ssen lediglich $\gamma$ und $\nabla_\mathbf{w} E_D$(im Code \mintinline{julia}|âˆ‡ğ°_prior|) als neue Parameter hinzugefÃ¼gt werden und die RÃ¼ckgabe so angepasst, dass in jeder Iteration ein 2-Tupel aus neuem Parametervektor und aktuellem Gradienten zurÃ¼ckgegeben wird. Dementsprechend muss auch die call-site in \mintinline{julia}|gd| angepasst werden.

\begin{listing}[!ht]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Gradient descent iteration
    # Args:
        Î¦: Basis Function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        ğ°: Parameters
        Î·: Learning rate
        âˆ‡ğ°_prior: Gradient of parameters from prior iteration
        Î³: Momentum factor
    """
    function gd_iteration(Î¦, ğ—, t, ğ°::Vector{<:Number}, Î·, âˆ‡ğ°_prior, Î³)
        M = size(ğ°)[1]
        âˆ‡ğ° = Î³ * âˆ‡ğ°_prior
        for j = 1:M
            âˆ‚E_Dâˆ‚w_jk(k) = âˆ‚E_Dâˆ‚w_k(Î¦, ğ—, t, ğ°, k)
            âˆ‡ğ° += collect(map(âˆ‚E_Dâˆ‚w_jk, 1:M))
        end
        (ğ° - Î· * âˆ‡ğ°, âˆ‡ğ°)
    end

    """Find regression model using gradient descent
    # Args:
        Î¦: Basis Function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        Î·: learning rate with which to train
        M: Number of model parameters
        iters: Number of iterations
        Îµ: Gradient descent stops once the difference between two iterations (ğ° and ğ°') is less than Îµ
        Î³: Momentum Parameter
    """
    function gd(Î¦, ğ—, t, Î·, M, iters, Îµ = 10e-12, Î³ = 0.9)
        ğ° = randn(M)
        âˆ‡ğ° = zero(ğ°)
        for i = 1:iters
            ğ°_old = ğ°
            (ğ°, âˆ‡ğ°) = gd_iteration(Î¦, ğ—, t, ğ°, Î·, âˆ‡ğ°, Î³)
            if norm(ğ°_old - ğ°) < Îµ || any(isnan.(ğ°)) || any(isinf.(ğ°))
                break
            end
        end
        ğ±->y(ğ°, Î¦, ğ±)
    end
  \end{minted}
  \caption{Funktionen \mintinline{julia}|gd_iteration| und \mintinline{julia}|gd| mit konjungiertem Gradientenabstieg}
  \label{listing:simplebreak}
\end{listing}

Nach \cite[S. 110]{Lippe} wird $\gamma$ mit einem Wert von $0.9$ vorbelegt. Die wohl grÃ¶ÃŸte Problematik des konjugierten Gradientenabstiegs ist wohl, dass der Fall auftreten kann, dass der Momentum-Term betragsmÃ¤ÃŸig grÃ¶ÃŸer als der aktuelle Gradient ist, jedoch das umgekehrte Vorzeichen besitzt. In diesem Fall wÃ¼rde sich der Fehler des Systems vergrÃ¶ÃŸern. Aufgrund dessen kann hier keine Konvergenz garantiert werden.
Ein kurzer Test (mit konstanter Lernrate und $\varepsilon=10E-12$) mit nur wenigen Datenpunkten zeigt folgende Daten:

\begin{tabular}{ccc}
  \toprule
  $\gamma$ & k bei Abbruch nach k Iterationen & Restfehler\\
  \midrule
  $0.0$ & $50544$ & $6.701991676725787$\\
  $0.5$ & $28837$ & $6.701991676725787$\\
  $0.9$ & $5635$ & $6.701991676725783$\\
\end{tabular}

Also gibt es durchaus FÃ¤lle, in denen durch dieses Verfahren eine enorme Steigerung bei der Konvergenzgeschwindigkeit erzielt wird.


\subsection{Adaptive Lernrate}
\subsection{Weight Decay}

\section{Beispiele}

\bibliographystyle{alphadin}
\bibliography{Quellen}

\end{document}