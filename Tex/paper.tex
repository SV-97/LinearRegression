\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[german]{babel} % prefer english over german
\usepackage{multicol}
\usepackage{tikz}
\usetikzlibrary{angles,arrows,babel,calc,patterns,quotes}

\usepackage{graphicx}
\graphicspath{ {./img/} }

\usepackage{minted}
\usepackage{xcolor}
\usemintedstyle{manni}

\usepackage{eurosym}
\usepackage{amstext}

\usepackage{booktabs}

\usepackage{amssymb, amsmath, amsthm, amsfonts}

\usepackage{ulem} % allows striking out text among other things

\usepackage{fontspec}

\usepackage{newunicodechar}

\newunicodechar{ùê∞}{$\textbf{w}$}
\newunicodechar{ùê±}{$\textbf{x}$}
\newunicodechar{‚Çô}{${}_n$}
\newunicodechar{ùêó}{$\textbf{X}$}
\newunicodechar{‚Çñ}{${}_k$}
\newunicodechar{‚àá}{$\nabla$}

%\usepackage[santa]{realhats}

\setmonofont[
  Mapping=tex-text,
  Scale=0.90,
  UprightFont=*-Regular,
  BoldFont=*-Bold,
  ]{Fira Code}
%\setmonofont[Mapping=tex-text, Scale=0.90,]{Droid Sans Mono}

\theoremstyle{plain} %Text ist Kursiv
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Korollar}

\theoremstyle{definition} %Text ist \"upright"
\newtheorem{remark}[theorem]{Bemerkung}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Beispiel}
\newtheorem{algo}[theorem]{Algorithm}
\newtheorem{problem}[theorem]{Problem}
\let\proof\undefined
\newtheorem{proof}[theorem]{Beweis}
\newtheorem{theo}[theorem]{Satz}
\newtheorem{anno}[theorem]{Anmerkung}
\newtheorem{solution}[theorem]{L√∂sung}

% Colors
\definecolor{bg}{rgb}{0.95,0.95,0.95}

\newcommand{\sfloor}[1]{\left\lfloor #1 \right\rfloor} % scaling floor function
\newcommand{\sceil}[1]{\left\lceil #1 \right\rceil} % scaling ceil function
\newcommand{\floor}[1]{\lfloor #1 \rfloor} % floor function
\newcommand{\ceil}[1]{\lceil #1 \rceil} % ceil function
\newcommand{\specialset}[1]{\rm I\!#1} % render sets like R and N fancy
\newcommand{\abs}[1]{\left\lVert#1\right\rVert} % Absolute value of #1
\newcommand{\unit}[1]{\hat{#1}} % unit vector

\title{ Mehrdimensionales Datenfitting mit linearer Regression }

\rhead{\includegraphics[width=1.5cm]{FHWS}}
\lhead{}

\author{
  Stefan Volz\\
  Fakult√§t f√ºr angewandte Natur- und Geisteswissenschaften\\
  Hochschule f√ºr angewandte Wissenschaften W√ºrzburg-Schweinfurt\\
  Studiengang Technomathematik\\
  Matrikelnummer: 3519001\\
  \texttt{stefan.volz@student.fhws.de}\\
}

\date{\today, Wintersemester 2019}

%\renewcommand{\headeright}{Studienarbeit}
%\renewcommand{\undertitle}{Studienarbeit}

\begin{document}

\begin{center}
  \includegraphics[width=0.5\textwidth]{FHWS}  
\end{center}

\maketitle

\begin{abstract}
  In vielen Anwendungen ist es n√∂tig/vorteilhaft aus Messdaten ein mathematisches Modell zu entwickeln, welches m√∂glichst Messungenauigkeiten ausgleicht bzw. Vorhersagen zul√§sst. Ziel der Arbeit ist die Implementierung von linearer Regression. Hierbei soll mittels Gradientenabstieg eine Fehlerminimierung des Modells im Bezug auf gegebene Messdaten durchgef√ºhrt werden und anschlie√üend am Beispiel von BFGS ein Ausblick auf komplexere Optimierungsverfahren gegeben werden. Die Implementierung erfolgt in Julia.
\end{abstract}

\tableofcontents
\newpage

\section{Konventionen und Generelles}
\subsection{Wahl der Programmiersprache und Abh√§ngigkeiten}
Die Implementierung erfolgt in Julia\footnote{\url{https://julialang.org/}}. Julia ist eine hochperformante, stark und dynamisch typisierte, √ºberwiegend imperative Programmiersprache mit Fokus auf wissenschaftlichem Rechnen; ist jedoch im Gegensatz zu z.B. MATLAB als General Purpose Sprache zu verstehen. Die Arbeit benutzt Julia in Version 1.2.0. Die Abh√§ngigkeiten beschr√§nken sich auf das \texttt{Plots} Package\footnote{\url{https://docs.juliaplots.org/}} - jedoch ist die eigentliche Logik abh√§ngigkeitsfrei.

Die Wahl der Sprache fiel auf Julia, da es nativ eine sehr gute Unterst√ºtzung f√ºr Matrizen mitbringt was f√ºr die Implementierung als sehr vorteilhaft angesehen wird. Au√üerdem erlaubt der gute Unicode-Support es, Identifier so zu w√§hlen, dass diese nah an der Fachliteratur sind. Desweiteren ist die immense Performancesteigerung gegen√ºber beispielsweise Python ein gro√ües Plus. Syntaktisch und semantisch sollte Julia f√ºr Leser, die eine andere dynamische Hochsprache (z.B. Python, Matlab, Ruby) beherrschen kein Problem sein - spezielle Sprachfeatures werden i.d.R. in Fu√ünoten kurz erkl√§rt.

\subsection{Quellcode}
Beim Code wird darauf geachtet, die Typannotationen\footnote{\url{https://docs.julialang.org/en/v1/manual/types/}} von Julia zu nutzen, da diese zum einfacheren Verst√§ndnis des Codes beitragen und au√üerdem der Performance zutr√§glich sind.
Identifier werden gr√∂√ütenteils so gew√§hlt, dass sie sich mit \cite{Bishop} decken - teils werden jedoch auch Bezeichner aus \cite{Lippe} √ºbernommen. Der Code wird unter \url{https://github.com/SV-97/LinearRegression} gehostet.

\subsection{Text dieser Arbeit}
Im Text der Arbeit werden - in Anlehnung an \cite{Bishop} - folgende Konventionen genutzt:

\begin{tabular}{llc}
  \toprule
  Typ & Beschreibung & Beispiel \\
  \midrule
  vektorielle Gr√∂√üen & fettgedruckte Kleinbuchstaben & $\mathbf{w}$ \\
  einzelne Elemente eines Vektors & indizierte Kleinbuchstaben & $w_j$ \\
  Matrizen und Mengen & Gro√übuchstaben & $A$ \\
  Hyperparameter des Modells & griechische Kleinbuchstaben & $\gamma$ \\
  sonstige Parameter & lateinische Kleinbuchstaben & $x$ \\
  Code listings und Quellcode-Referenzen & monospace font & \mintinline{julia}|code| \\
\end{tabular}

Einzelne Indizes an Matrixen wie z.B. $A_j$ sind als Zeilenindizes zu verstehen, sodass $A_j$ die j-te Zeile von $A$ ist.
In einigen F√§llen wird zwecks Konsistenzwahrung mit \cite{Bishop} oder der zum jeweiligen Thema geh√∂rigen Literatur von diesen Konventionen abgewichen.
F√ºr eine Matrix $A$ steht $A^T$ f√ºr die Transponierte. Die Identit√§tsmatrix zu $\mathbb{R}^{n \times n}$ wird geschrieben als $I_n$.

\subsection{Variablenbezeichner}

Einige der wichtigsten Bezeichner sind hier aufgef√ºhrt:

\begin{tabular}{cl}
  \toprule
  Bezeichner & Beschreibung\\
  \midrule
  $d$ & Dimension eines Eingabevektors\\
  $k$ & Dimension eines Zielwertsvektors\\
  $M$ & Anzahl der Modellparameter\\
  $N$ & Anzahl der Trainingsdatens√§tze\\
  $X$ & Trainingseingabematrix\\
  $T/\mathbf{t}$ & Trainingszielmatrix/Trainingszielvektor\\
  $\mathbf{w}$ & Modellparameter\\
\end{tabular}


\section{Grundlegende Implementierung}
\subsection{Problemformulierung}
Seien $d,k,M,N \in \mathbb{N}$ mit Messdaten $X \in \mathbb{R}^{d \times N}$ und zugeh√∂rigen Zielwerten $T \in \mathbb{R}^{k \times N}$ gegeben. Gesucht werden die Parameter $\mathbf{w}$ eines Modells $y(\mathbf{w}, \mathbf{x})$ mit $y \in \mathbb{R}^M \times \mathbb{R}^d \rightarrow \mathbb{R}^{k}$ welche das Minimierungsproblem
$$
    \min_{\mathbf{w} \in \mathbb{R}^M}\sum_{i=1}^N E(y(\mathbf{w}, X_{i}), T_{i}),
$$
im Bezug auf eine Fehlerfunktion $E: \mathbb{R}^k \times \mathbb{R}^k \rightarrow \mathbb{R}$ l√∂sen.

Wir betrachten zun√§chst nur Probleme f√ºr die $k=1$ gilt und bezeichnen daher die Zielwerte mit $\mathbf{t}$.

\subsection{Lineare Regression}
\subsubsection{Mathematische Grundlagen}
Bei linearer Regression handelt es sich um eine Methode des √ºberwachten Lernens.
\begin{definition}
  Lineare Regressions Modelle sind Modelle, welche sich im Bezug auf ihre Modellparameter linear verhalten\cite[S. 137f]{Bishop}. Sie stellen Funktionen der Form $y: \mathbb{R}^M \times \mathbb{R}^d \rightarrow \mathbb{R}^k, (\mathbf{w}, \mathbf{x}) \mapsto y(\mathbf{w}, \mathbf{x})$ dar. Die Anzahl der Modellparameter ist gegeben durch $M \in \mathbb{N}$, die Anzahl an Eingangsgr√∂√üen durch $d \in \mathbb{N}$ und die der Zielgr√∂√üen durch $k \in \mathbb{N}$.
\end{definition}
\begin{anno}
  Dies bedeutet nicht, dass sie auch zwingend linear im Bezug auf die Eingangsvariablen sein m√ºssen.
\end{anno}

Das einfachste lineare Regressions Modell ist eine Linearkombination der Eingangsvariablen 
$$
  y(\mathbf{w}, \mathbf{x}) = w_0 + w_1x_1 + w_2x_2 + \hdots + w_Dx_D,
$$
diese spiegeln jedoch oftmals nicht die zugrunde-liegende Verteilung der realen Messwerte wider, und limitieren ein Modell mit $d$ Eingangsvariablen auf $d+1$ Modellparameter. Daher werden Basisfunktionen eingef√ºhrt und Lineare Regressions Modelle als Linearkombination dieser gebildet.
\begin{definition}
  Eine Funktion $\Phi_j: \mathbb{R}^d \rightarrow \mathbb{R}^k, \mathbf{x} \mapsto \Phi_j(\mathbf{x})$ bezeichnen wir als Basisfunktion.
\end{definition}
\begin{anno}
  Im Code werden Basisfunktionen als Funktionen $\Phi: \mathbb{N} \times \mathbb{R}^d \rightarrow \mathbb{R}^k, (j, \mathbf{x}) \mapsto \Phi(j, \mathbf{x})$ implementiert.
\end{anno}

Mit diesen Basisfunktionen ergibt sich als Modellgleichung
$$
  y(\mathbf{w}, \mathbf{x}) = w_0 + \sum_{j=1}^{M-1}w_j\Phi_j(\mathbf{x}),
$$
wobei der Parameter $w_0$ auch als Bias-Parameter bezeichnet wird, da er einen festen Offset der Daten erm√∂glicht. Im Code betrachten wir diesen Bias-Parameter als ``normalen'' Parameter und w√§hlen als kleinsten Index in $\mathbf{w}$ Eins. Ein eingangsvariablenunabh√§ngiger Offset ist leicht durch eine angepasste Definition der Basisfunktion erreichbar:
\[ \Phi: (j, \mathbf{x}) \mapsto
 \left\{
  \begin{array}{ll}
    1,& j=1, \\
    \Phi_j(\mathbf{x}), & sonst. \\  
  \end{array}
\right. \]

Damit vereinfacht sich die Darstellung der Modellgleichung zu
\begin{align}
  y(\mathbf{w}, \mathbf{x}) = \sum_{j=1}^{M}w_j\Phi(j, \mathbf{x}). \label{y}
\end{align}

\subsubsection{Implementierung}
Auf Basis dieser Formulierungen k√∂nnen wir mit der Implementierung beginnen.
Hierzu definieren wir uns zun√§chst eine Funktion \texttt{$\Sigma$} um alle im Code vorkommenden Summen zu abzudecken.

\begin{listing}[H] % maybe use [!ht] instead?
    \begin{minted}[bgcolor=bg]{julia}
        "Sum from k=`from` to `to` of `a(k)`"
        Œ£(from::Integer, to::Integer, a::Function, zero = 0) =
          mapreduce(a, (+), from:to; init = zero)
    \end{minted}
    \caption{Funktion \mintinline{julia}|Œ£|}
\end{listing}

Die Funktion ist hierbei eine Implementierung von $\sum_{k=\text{from}}^\text{to}a(k)$. Bei \texttt{mapreduce} handelt es sich um eine eingebaute Funktion welche (hier) erst \texttt{a} √ºber eine Sequenz mappt und anschlie√üend diese Sequenz mittels \texttt{(+)} reduziert/faltet. Dabei ist \texttt{(+)} der eingebaute Additionsoperator. Der optionale Parameter \texttt{zero} erlaubt es die Funktion auch f√ºr nicht-skalare Summen(bzw. jegliche Typen f√ºr die eine Implementierung zu \texttt{+} existiert) zu nutzen.

\begin{listing}[H]
    \begin{minted}[bgcolor=bg]{Julia}
      """Linear Regression
      # Args:
          ùê∞: Parameters
          Œ¶(j, ùê±): Basis function of type (Int, Vector{T}) -> T
          ùê±: Input vector
      """
      function y(
        ùê∞::Vector{<:Number},
        Œ¶::(T where T <: Function),
        ùê±::Vector{<:Number})::Number
          Œ£(1, size(ùê∞)[1], j->ùê∞[j] * Œ¶(j, ùê±))
      end
    \end{minted}
    \caption{Funktion \mintinline{julia}|y|}
    \label{listing:y}
\end{listing}

Diese Implementierung der Funktion \texttt{y} passt 1:1 zur mathematischen Formulierung in Gleichung \ref{y}\footnote{Die in Listing \ref{listing:y} genutzte Schreibweise \mintinline{julia}|Vector{<:Number}| bedeutet \emph{Vektor eines Typen T, wobei T ein Subtyp des abstrakten Typs Number ist}. Diese hat gegen√ºber \mintinline{julia}|Vector{Number}| den Vorteil, dass sie gewisse Optimierungen erm√∂glicht(Im Detail erlaubt \mintinline{Julia}|<:| Julia mit unboxed Werten zu arbeiten).}.

\subsection{Die Fehlerfunktion}

Als n√§chstes ben√∂tigen wir eine M√∂glichkeit um den Fehler des Systems zu ermitteln - sodass wir diesen im n√§chsten Schritt minimieren k√∂nnen. Die genutzte Fehlerfunktion ist die des quadratischen Fehlers. Nach \cite[S. 140f]{Bishop} ergibt sich die Fehlerfunktion
\begin{align}
    E_D := \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, \mathbf{x}))^2.
\end{align}

Mit dieser Definition k√∂nnen wir nun unser Minimierungsproblem wie folgt definieren:
$$
  \min_{\mathbf{w} \in \mathbb{R}^M} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, X_n))^2.
$$
Im n√§chsten Schritt werden wir ein Verfahren implementieren, das diese Minimierung durchf√ºhrt.

\subsection{Gradientenabstiegsverfahren}

\subsubsection{Mathematische Grundlagen}

Das Gradientenabstiegsverfahren ist ein numerisches Verfahren mit dem sich allgemeine Optimierungsprobleme l√∂sen lassen. Beim Gradientenabstiegsverfahren bestimmen wir den Gradienten von $E_D$ im Bezug auf die Modellparameter $\mathbf{w}$ - diesen Gradienten bezeichnen wir mit $\nabla_\mathbf{w} E_D$. Hierzu bestimmen wir zun√§chst die partielle Ableitungen von $E_D$ nach allen $w_k$ aus $\mathbf{w}$.
$$
  \frac{\partial E_D}{\partial \mathbf{w}_k} = \frac{\partial}{\partial \mathbf{w}_k} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, \mathbf{x}))^2 = - \sum_{n=1}^N \Phi(k, X_n) \cdot (\mathbf{t}_n - y(\mathbf{w}, \Phi, X_n))
$$
Der Gradient ist dann
$$
  \nabla_\mathbf{w} E_D
    = \left( \begin{array}{c}
      \frac{\partial E_D}{\partial \mathbf{w_1}}\\
      \vdots\\
      \frac{\partial E_D}{\partial \mathbf{w_M}}\\
      \end{array} \right).
$$

Um diesen Gradienten zu implementieren, beginnen wir mit der Implementierung der partiellen Ableitung:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Derivative of E_D with respect to ùê∞‚Çñ
    # Args:
        Œ¶(k, ùê±‚Çô): Basis function
        ùêó: Set of inputs ùê±‚Çô where ùê±‚Çô is an input vector to Œ¶
        t: corresponding target values for each ùê±‚Çô
        k: Index for ùê∞‚Çñ in respect to which the derivative is taken
        ùê∞: Parameters
    """
    function ‚àÇE_D‚àÇw_k(
      Œ¶::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      ùê∞::Vector{<:Number},
      k::Integer)::Number
        N = size(t)[1]
        - Œ£(1, N, n->Œ¶(k, ùêó[n, :]) * (t[n] - y(ùê∞, Œ¶, ùêó[n,:])))
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|‚àÇE_D‚àÇw_k|}
  \label{listing:partial}
\end{listing}

\subsubsection{Einzeliteration des Gradientenabstiegs}

Hiermit k√∂nnen wir eine Iteration des Gradientenabstiegsalgorithmus wie folgt implementieren.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """One iteration of the gradient descent algorithm
    # Args:
        ‚àÇE_D‚àÇw_k: Partial derivative of error function with respect to
            the k-th parameter
        ùêó: Column vector of inputs ùê±‚Çô where ùê±‚Çô is an input vector to the
            error function
        t: corresponding target values for each ùê±‚Çô
        ùê∞: Parameters
        Œ∑: Learning rate
    """
    function gradient_descent_iteration(
      ‚àÇE_D‚àÇw_k::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      ùê∞::Vector{<:Number},
      Œ∑::Number)::Vector{<:Number}
        M = size(ùê∞)[1]
        ‚àáùê∞ = zero(ùê∞)
        for j = 1:M
            ‚àÇE_D‚àÇw_jk(k) = ‚àÇE_D‚àÇw_k(ùêó, t, ùê∞, k)
            ‚àáùê∞ += collect(map(‚àÇE_D‚àÇw_jk, 1:M))
        end
        ùê∞ - Œ∑ * ‚àáùê∞
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent_iteration|}
  \label{listing:gd_iteration}
\end{listing}

Innerhalb der Funktion iterieren wir √ºber alle Indizes $j$, bilden die partielle Ableitung nach $\mathbf{w}_k$\footnote{Achtung: Die hier genutzte Funktion ist nicht die des globalen Scopes, sondern ein Parameter der Funktion.} und berechnen ihren Wert f√ºr alle Komponenten des Ergebnisvektors. Der Gradient ist dann die Summe all dieser Vektoren. In der letzten Zeile der Funktion machen wir einen ''Schritt'' in Richtung des Gradienten - steigen auf der Fehlerkurve also ab. Die Schrittweite wird hierbei durch den Hyperparameter $\eta$ gesteuert. Dieser als Lernrate bezeichnete Parameter steuert im Grunde genommen die Konvergenzgeschwindigkeits des Gradientenabstiegsverfahrens.

\subsubsection{Hauptfunktion}

Auf Basis dieser Funktion k√∂nnen wir nun den Rest des Algorithmus in der Funktion \mintinline{julia}|gradient_descent| umsetzen.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Minimize function E_D(ùêó, t, ùê∞)
    # Args:
        ‚àÇE_D‚àÇw_k: Partial derivative of error function with respect to
            the k-th parameter
        ùêó: Column vector of inputs ùê±‚Çô where ùê±‚Çô is an input vector to the
            error function
        t: corresponding target values for each ùê±‚Çô
        ùê∞: Initial parameters - usually `randn(M)`
        Œ∑: Learning rate
        M: Number of model parameters
        iters: Number of iterations
    """
    function gradient_descent(
      ‚àÇE_D‚àÇw_k::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      Œ∑::Number,
      M::Integer,
      iters::Integer,
      ùê∞::Vector{<:Number})::Vector{<:Number}
        ‚àáùê∞ = zero(ùê∞)
        for i = 1:iters
            ùê∞ = gradient_descent_iteration(‚àÇE_D‚àÇw_k, ùêó, t, ùê∞, Œ∑)
        end
        ùê∞
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent|}
  \label{listing:gd}
\end{listing}

Diese Funktion ruft \mintinline{julia}|iters|-mal die Hilsfunktion \mintinline{julia}|gradient_descent_iteration| auf und updated die Parameter mit dem Ergebnis dieser Aufrufe. Nach Ende der Optimierung gibt sie die als optimal befundenen Werte der Parameter zur√ºck. 
\newpage
Der Aufruf von \mintinline{julia}|gradient_descent| erfolgt aus der Funktion \mintinline{julia}|fit_linear_model| heraus.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Find regression model 
    # Args:
        Œ¶: Basis Function
        ùêó: Set of inputs ùê±‚Çô where ùê±‚Çô is an input vector to Œ¶
        t: corresponding target values for each ùê±‚Çô
        Œ∑: learning rate with which to train
        M: Number of model parameters
        iters: Number of iterations
        optimizer: Parameter to select optimizer that's used
    # Fails:
        On unknown optimizers or error inside the optimizer
    """
    function fit_linear_model(
      Œ¶::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      Œ∑::Number,
      M::Integer,
      iters::Integer,
      optimizer = :gradient_descent)::Tuple{Function,Number}
        if optimizer == :gradient_descent
            ùê∞ = gradient_descent(
              (ùêó, t, ùê∞, k)->‚àÇE_D‚àÇw_k(Œ¶, ùêó, t, ùê∞, k),
              ùêó, t, Œ∑, M, iters, randn(M), Œµ, Œ≥)
            residual_error = E_D(Œ¶, ùêó, t, ùê∞)
            (ùê±->y(ùê∞, Œ¶, ùê±), residual_error)
        else
            error("Invalid optimizer")
        end
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|fit_linear_model|}
  \label{listing:gd}
\end{listing}

Diese Funktion stellt im Grunde genommen nur einen Treiber f√ºr den Optimizer da. Sie initialisiert die Modellparameter zu Beginn mit einem Vektor aus normalverteilten Zufallszahlen\cite{Lippe} aus dem Intervall $[-1, 1]$. Nach der Optimierung gibt sie das vollendete Modell als Closure\footnote{Eine Closure ist eine anonyme Funktion welche intern eine Referenz auf ihren Erstellungskontext h√§lt. Hier wird sie eingesetzt um \mintinline{julia}|y| mit \mintinline{julia}|ùê∞| und \mintinline{julia}|Œ¶| partiell zu evaluieren.} zur√ºck, was dem die Funktion Aufrufenden erm√∂glicht, Modellaussagen in Abh√§ngigkeit eines Eingangsvektors zu erhalten. Au√üerdem bestimmt sie den Restfehler des Modells und gibt auch diesen zur√ºck. Der Parameter \mintinline{julia}|optimizer| ist bisher noch nicht in Benutzung, da nur ein Optimizer implementiert ist\footnote{\mintinline{julia}|:abc| ist ein Symbol-Literal. Diese Symbole sind vergleichbar mit denen in Ruby und Scheme oder auch Atomen in Erlang und Prolog. (siehe \url{https://docs.julialang.org/en/v1/manual/metaprogramming/})}.

\subsubsection{Abbruchkriterium}

Die Grundimplementierung wird mit einem einfachen Abbruchkriterium abgeschlossen. Hierbei wird zu jeder Iteration gepr√ºft, ob die Norm der Differenz der Parametervektoren von zwei aufeinanderfolgenden Iterationen kleiner als ein neuer Hyperparameter $\varepsilon$ ist - in Formeln ausgedr√ºckt: es wird gepr√ºft ob $||\mathbf{w} - \mathbf{w}'||_2 < \varepsilon$ gilt.
Au√üerdem wird gepr√ºft ob einer der Parameter zu $\pm\infty$ divergiert (und das Verfahren somit ''fehlgeschlagen'') ist oder durch einen Rechenfehler ein \mintinline{julia}|NaN|\footnote{\emph{Not a Number} - spezieller Wert von IEEE floats} in $\mathbf{w}$ aufgetaucht ist. In all diesen F√§llen wird der Algorithmus vorzeitig abgebrochen. Sofern kein Fehler vorliegt werden die Modellparameter zur√ºckgegeben\footnote{Der Punkt im Funktionsaufruf in Listing \ref{listing:simplebreak} sorgt daf√ºr, dass die Funktion vektorisiert/\emph{pointwise} aufgerufen wird (siehe \url{https://docs.julialang.org/en/v1/manual/functions/}).}. Au√üerdem √§ndert sich der R√ºckgabewert der Funktion diesbez√ºglich, dass sie nun zur√ºckgibt wieviele Iterationen tats√§chlich durchlaufen wurden.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Minimize function E_D(ùêó, t, ùê∞)
    # Args:
        ‚àÇE_D‚àÇw_k: Partial derivative of error function with respect to
            the k-th parameter
        ùêó: Column vector of inputs ùê±‚Çô where ùê±‚Çô is an input vector to the
            error function
        t: corresponding target values for each ùê±‚Çô
        ùê∞: Initial parameters - usually `randn(M)`
        Œ∑: Learning rate
        M: Number of model parameters
        iters: Number of iterations
        Œµ: Gradient descent stops once the difference between two iterations
            (ùê∞ and ùê∞') is less than Œµ

    # Fails:
        Fails on encountering NaN in computation or on Divergence to Inf
    """
    function gradient_descent(
      ‚àÇE_D‚àÇw_k::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      Œ∑::Number,
      M::Integer,
      iters::Integer,
      ùê∞::Vector{<:Number},
      Œµ = 10e-12::Number)::Tuple{Vector{<:Number},Integer}
        did_iters = 0
        for i = 1:iters
            did_iters += 1
            ùê∞_old = ùê∞
            ùê∞ = gradient_descent_iteration(‚àÇE_D‚àÇw_k, ùêó, t, ùê∞, Œ∑, ‚àáùê∞, Œ≥)
            if any(isnan.(ùê∞))
              error("Encountered NaN") 
            end
            if any(isinf.(ùê∞))
                error("Divergence in calculation")
            end
            if norm(ùê∞_old - ùê∞) < Œµ
                break
            end
        end
        (ùê∞, did_iters)
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent| mit einfachem Abbruchkriterium}
  \label{listing:simplebreak}
\end{listing}

F√ºr den Parameter $\varepsilon$ wird eine arbitr√§r gew√§hlte Standartbelegung von $10\cdot10^{-12}$ gesetzt. Ein weiteres denkbares und oft genutztes Abbruchkriterium ist die √úberpr√ºfung, ob die Norm des Gradienten ungef√§hr Null ist.

\section{Fortgeschrittene Features}
\subsection{Momentum Verfahren}
Das Momentum Verfahren ist eine Adaption des Gradientenabstiegs, welche die Konvergenzgeschwindigkeit erh√∂hen soll. Das Ziel ist es, auf flachen Bereichen der Fehlerkurve die Abstiegsgeschwindigkeit zu erh√∂hen und sie in steilen Passagen zu verringern. Das Verfahren l√§sst sich als ein Ball der eine Kurve hinabrollt visualisieren - dieser verh√§lt sich bei √Ñnderungen der Kurve mit einer gewissen Tr√§gheit.
Um eine solche Tr√§gheit zu realisieren wird ein Momentum-Term hinzugef√ºgt. Dieser Term ist das Produkt des Gradienten der vorhergehenden Iteration und eines neuen Hyperparameters $\gamma \in [0,1)$ - dem Tr√§gheitsfaktor. Der Gradient $\nabla_\mathbf{w}\hat{E_D}$ in jeder Iteration ergibt sich dann aus dem eigentlichen Gradienten dieser Iteration $\nabla_\mathbf{w} E_D'$ sowie dem der vorhergehenden Iteration $\nabla_\mathbf{w} E_D$ multipliziert mit dem Momentum-Faktor $\gamma$.
$$
  \nabla_\mathbf{w} \hat{E}_D = \nabla_\mathbf{w} E_D' + \gamma \nabla_\mathbf{w} E_D
$$
Zur Implementierung m√ºssen lediglich $\gamma$ und $\nabla_\mathbf{w} E_D$(im Code \mintinline{julia}|‚àáùê∞_prior|) als neue Parameter hinzugef√ºgt werden und die R√ºckgabe so angepasst, dass in jeder Iteration ein 2-Tupel aus neuem Parametervektor und aktuellem Gradienten zur√ºckgegeben wird. Dementsprechend m√ºssen auch die call sites in \mintinline{julia}|gradient_descent| sowie \mintinline{julia}|fit_linear_model| angepasst werden. Da die √Ñnderungen an den call sites trivial sind ist hier nur \mintinline{julia}|gradient_descent_iteration| aufgef√ºhrt.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """One iteration of the gradient descent algorithm
    # Args:
        ‚àÇE_D‚àÇw_k: Partial derivative of error function with respect to
            the k-th parameter
        ùêó: Column vector of inputs ùê±‚Çô where ùê±‚Çô is an input vector to the
            error function
        t: corresponding target values for each ùê±‚Çô
        ùê∞: Parameters
        Œ∑: Learning rate
        ‚àáùê∞_prior: Gradient of parameters from prior iteration
        Œ≥: Momentum factor
    """
    function gradient_descent_iteration(
      ‚àÇE_D‚àÇw_k::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      ùê∞::Vector{<:Number},
      Œ∑::Number,
      ‚àáùê∞_prior::Vector{<:Number},
      Œ≥::Number)::Tuple{Vector{<:Number},Vector{<:Number}}
        M = size(ùê∞)[1]
        ‚àáùê∞ = Œ≥ * ‚àáùê∞_prior
        for j = 1:M
            ‚àÇE_D‚àÇw_jk(k) = ‚àÇE_D‚àÇw_k(ùêó, t, ùê∞, k)
            ‚àáùê∞ += collect(map(‚àÇE_D‚àÇw_jk, 1:M))
        end
        (ùê∞ - Œ∑ * ‚àáùê∞, ‚àáùê∞)
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent_iteration| mit Momentum Verfahren}
  \label{listing:momentum}
\end{listing}

Nach \cite[S. 110]{Lippe} wird $\gamma$ mit einem Wert von $0.9$ vorbelegt. Die wohl gr√∂√üte Problematik dieses Verfahrens ist, dass der Fall auftreten kann das der Momentum-Term betragsm√§√üig gr√∂√üer als der aktuelle Gradient ist, jedoch das umgekehrte Vorzeichen besitzt. In diesem Fall w√ºrde sich der Fehler des Systems vergr√∂√üern. Aufgrund dessen kann hier keine Konvergenz garantiert werden.
Ein kurzer Test\footnote{Die Funktion mit der getestet wurde ist $x \mapsto x^2+\theta_x$, wobei $\theta_x$ ein Wert aus einem normalverteilten Rauschen von $-3$ bis $+3$ ist.} (mit konstanter Lernrate und \texttt{Œµ=10e-12} mit nur wenigen Datenpunkten zeigt folgende Daten\footnote{Details zur Messung in Anhang \ref{appendix:measure}. Es ist zu beachten, dass der insgesamt allokierte Speicher dargestellt ist.}:

\begin{center}
  \begin{tabular}{cccccc}
    \toprule
    $\gamma$ & k bei Abbruch & Restfehler bei Abbruch & Laufzeit & Gesamt allokierter & Garbage Collector\\
    &  nach k Iterationen & des Algorithmus & (in Sekunden) & Speicher (in MiB) & Zeitanteil (in \%) \\
    \midrule
    $0.0$ & $50544$ & $6.701991676725787$ & $0.80471$ & $890.111$ & $9.37$ \\
    $0.5$ & $28837$ & $6.701991676725787$ & $0.43627$ & $463.782$ & $9.46$ \\
    $0.9$ & $5635$ & $6.701991676725783$ & $0.07825$ & $99.488$ & $8.39$ \\
  \end{tabular}
\end{center}

Also gibt es durchaus F√§lle, in denen durch dieses Verfahren eine enorme Steigerung bei der Konvergenzgeschwindigkeit erzielt wird. Jedoch sehen die Verl√§ufe der Kurven von Restfehler und Gradient wie folgt aus:

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_0_Error_10e-12_Crop}
  \caption{Beispielfit mit $\gamma=0$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_5_Error_10e-12_Crop}
  \caption{Beispielfit mit $\gamma=0.5$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_9_Error_10e-12_Crop}
  \caption{Beispielfit mit $\gamma=0.9$}
\end{figure}

Es ist klar zu sehen, dass der oben genannte 'worst case' im Fall $\gamma=0.9$ eingetreten ist. Das vermeintlich bessere Konvergenzverhalten lag daran, dass ein sehr geringes $\varepsilon$ gew√§hlt wurde. Erh√∂hen wir $\varepsilon$ auf beispielsweise \texttt{10e-3}, dann ergeben sich die folgenden Werte\footnote{Die GC Werte sind gestrichen, da sie sich nicht f√ºr alle Testdurchl√§ufe bestimmen  lie√üen (\mintinline{Julia}|@time| liefert bei zu kurzen Durchl√§ufen nicht zwingend alle Werte - evtl. liefert es keinen Wert falls w√§hrend des Messvorgangs keine GC-Iteration vorlag. Die angegebenen Werte sind das Mittel aus drei Iterationen in denen ein GC-Wert vorlag.)}:

\begin{center}
  \begin{tabular}{cccccc}
    \toprule
    $\gamma$ & k bei Abbruch & Restfehler bei Abbruch  & Laufzeit & Gesamt allokierter & Garbage Collector\\
    &  nach k Iterationen & des Algorithmus & (in Sekunden) & Speicher (in MiB) & Zeitanteil (in \%) \\
    \midrule
        $0.0$ & $24$ & $10.216203809068343$ & $0.00581$ & $1.398$ & \sout{$61.54$} \\
        $0.5$ & $14$ & $6.813835951850837$  & $0.00570$ & $1.232$ & \sout{$48.19$} \\
        $0.9$ & $29$ & $36.63725946510655$  & $0.00680$ & $1.438$ & \sout{$60.92$} \\
  \end{tabular}
\end{center}

beziehungsweise folgende Graphen:

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_0_Error_10e-3}
  \caption{Beispielfit mit $\gamma=0$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_5_Error_10e-3}
  \caption{Beispielfit mit $\gamma=0.5$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_9_Error_10e-3}
  \caption{Beispielfit mit $\gamma=0.9$}
\end{figure}

Das Momentumverfahren wirkt sich hier also teils positiv und teils negativ aus - bei der Wahl der Parameter ist vorsicht geboten.

\subsection{Tichonow Regularisierung}
Eine weitere M√∂glichkeit der Verbesserung des Verfahrens ist die \emph{Tichonow Regularisierung}. Das Ziel dieses Verfahrens ist es, die Stabilit√§t des Modells zu verbessern. Dabei wird das Minimierungsproblem wie folgt neu formuliert:
$$
  \min_{\mathbf{w} \in \mathbb{R}^M} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, X_n))^2 + \omega ||\mathbf{w}||^2_2.
$$
Es werden also zu gro√üe Werte in $\mathbf{w}$ ''bestraft''. Hierbei ist $\omega$ ein neuer Hyperparameter welcher festlegt wie ''wichtig'' die Minimierung des Parametervektors ist. Die neue partielle Ableitung ist damit:
$$
  \frac{\partial E_{D, decay}}{\partial \mathbf{w}_k} = - \sum_{n=1}^N \Phi(k, X_n) \cdot (\mathbf{t}_n - y(\mathbf{w}, \Phi, X_n)) - \omega \mathbf{w}_k
$$

Die erforderlichen √Ñnderungen am Code sind das Durchschleifen des Parameters $\omega$ und die Anpassung der partielle Ableitung:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """Derivative of E_D with respect to ùê∞‚Çñ
    # Args:
        Œ¶(k, ùê±‚Çô): Basis function
        ùêó: Set of inputs ùê±‚Çô where ùê±‚Çô is an input vector to Œ¶
        t: corresponding target values for each ùê±‚Çô
        ùê∞: Parameters
        k: Index for ùê∞‚Çñ in respect to which the derivative is taken
        œâ: Weight decay factor
    """
    function ‚àÇE_D‚àÇw_k(Œ¶::Function,
      ùêó::Matrix{<:Number},
      t::Vector{<:Number},
      ùê∞::Vector{<:Number},
      k::Integer,
      œâ::Real)::Number
        N = size(t)[1]
        - Œ£(1, N, n->Œ¶(k, ùêó[n, :]) * (t[n] - y(ùê∞, Œ¶, ùêó[n,:])) - œâ*ùê∞[k])
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|‚àÇE_D‚àÇw_k| mit Tichonow Regularisierung}
  \label{listing:decay}
\end{listing}

\subsection{Ausblick auf den Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno Algorithmus}

Der Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno - oder kurz BFGS - Algorithmus, ist ein Optimierungsverfahren aus der Gruppe der Quasi-Newton Verfahren. Nach \cite{Dai} ist BFGS der effizienteste Vertreter dieser Gruppe; so findet sich das Verfahren auch in vielen professionellen Softwaretoolboxes und Programmiersprachen wie z.B. R, Matlab oder auch SciPy wieder.
Ziel ist das l√∂sen des Optimierungsproblems $\min_{\mathbf{x} \in \mathbb{R}^n} f(\mathbf{x})$ mit $f: \mathbb{R}^n \rightarrow \mathbb{R}$.
Beginnend mit einem Startwert $\mathbf{x}_0$ und einer N√§herung der Hesse Matrix $B_0 := I_n$ werden folgende Schritte abgearbeitet. Dabei konvergiert $\mathbf{x}_k$ gegen die L√∂sung des Problems.

\begin{enumerate}
  \item{ Bestimmen einer Abstiegsrichtung $\mathbf{p}_k$ durch l√∂sen des LGS $B_k \cdot \mathbf{p}_k = - \nabla f(\mathbf{x}_k)$. }
  \item{ Sei $g_k: \mathbb{R} \rightarrow \mathbb{R}$ definiert durch $\alpha \mapsto f(x_k + \alpha \cdot p_k)$, dann ist die Schrittweite $\alpha_k > 0$ gegeben durch $\alpha_k = \arg \min_{\alpha \in \mathbb{R}} \frac{\partial g_k}{\partial \alpha}$.\\Dieses Minimierungsproblem wird mittels eines Liniensuchverfahrens (in der Implementierung wird hier zwecks Einfachheit das Gradientenabstiegsverfahren gew√§hlt - andere m√∂gliche Kandidaten w√§ren z.B. Newton Verfahren oder das CG-Verfahren) gel√∂st - wobei nur ein lokales Minimum gesucht wird\cite{Dai}.}
  \item {Setzen von $\mathbf{s}_k = \alpha_k \cdot \mathbf{p}_k$ und $\mathbf{x}_{k+1} = \mathbf{x}_k + \mathbf{s}_k$.}
  \item {Berechnung von $\mathbf{y}_k = \nabla f(\mathbf{x}_{k+1}) - \nabla f(\mathbf{x}_k)$.}
  \item {Neue N√§herung der Hesse Matrix $B$ nach der Rekursionsvorschrift $B_{k+1} = B_k + \frac{\mathbf{y}_k \mathbf{y}_k^T}{\mathbf{y}_k^T \mathbf{s}_k} - \frac{B_k \mathbf{s}_k \mathbf{s}_k^T B_k}{\mathbf{s}_k^T B_k \mathbf{s}_k}$ bestimmen.}
\end{enumerate}

Schritt 2 l√§sst sich so visualisieren, dass man die durch die Funktion beschriebene Figur mit der von Gradient und y-Achse aufgespannten Ebene schneidet - und dann das der aktuellen Position n√§heste lokale Minimum der dabei entstehenden Kurve sucht. Aus dieser √úberlegung folgt direkt, dass f√ºr einfache Probleme(z.B. $f(x,y) = x^2 + y^2$)(bei korrekter Parameterwahl) nach nur einem Schritt bereits eine L√∂sung gefunden wird.

\begin{figure}[t]
  \centering
  \includegraphics[width=.5\textwidth]{octave_contour_mod}
  \caption{Contourplot mit Visualisierung zu Schritt 2. Der rote Punkt zeigt die Startposition $x_k$, die blaue Linie einen Teil der durch $x_k + \alpha p_k$ beschriebenen Geraden. Durch eine eindimensionale Optimierung wird dann $\alpha_k$ so gew√§hlt, dass man bei einem Minimum(orange/braune Ellipse) landet. Originalbild von \url{https://octave.sourceforge.io/octave/function/images/contour_101.png}.}
\end{figure}

In Schritt 2 wird die Ableitung von $f(x_k + \alpha p_k)$ nach $\alpha$ ben√∂tigt - um diese nicht immer bestimmen zu m√ºssen, werden wir sie einfach numerisch n√§hern. Die Funktion \mintinline{Julia}|numeric_differentiation(f, h) = x -> (f(x + h) - f(x - h)) / (2 * h)| bestimmt mittels des zentralen Differenzquotienten die Ableitung einer eindimensionalen Funktion $f$.

Zum line search w√§hlen wir zu Demozwecken den bereits bekannten Gradientenabstieg - diesmal jedoch in allgemeiner Ausf√ºhrung und ohne Regularisierung etc..

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """Optimize some function f
    # Args:
        ‚àáf: Gradient of f
        x_0: Initial guess
        Œ∑: learning rate
        Œµ: cancellation tolerance
        max_iters: maximum number of iterations
    """
    function gradient_descent(‚àáf::Function,
      x_0,
      Œ∑::Number,
      Œµ::Number,
      max_iters::Integer)
        x_k = x_0
        count = 0
        for _ = 1:max_iters
            if any(isnan.(x_k))
                error("Encoutered NaN")
            end
            if any(isinf.(x_k))
                error("Encoutered Inf")
            end
            count += 1
            p_k = -‚àáf(x_k)
            if norm(‚àáf(p_k)) < Œµ
                break
            end
            x_k += Œ∑ * p_k
        end
        x_k
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent|}
  \label{listing:decay}
\end{listing}


Die liniensuchfunktionsagnostische Implementierung des BFGS-Algorithmus ist dann wie folgt:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """BFGS Optimization Algorithm

    # Args:
        ‚àáf: Gradient of function to optimize
        x_0: Initial guess for optimal value
        iters: Maximum number of iterations before cancellation
        line_search: Line search function that's used
        Œµ: Optimization stops once the norm of the gradient is below this value
    """
    function BFGS(
      f::Function,
      ‚àáf::Function, 
      x_0::Vector{<:Number}, 
      iters::Integer,
      line_search::Function,
      Œµ = 10e-12::Real)
        n = size(x_0)[1]
        x_k = x_0
        B_k = Matrix{typeof(x_0[1])}(I, n, n)

        for i = 1:iters
            if norm(‚àáf(x_k)) < Œµ
                break
            end
            # Step 1: obtain direction p_k by solving
            # B_k ‚àô p_k = - (gradient of f at x_k)
            p_k = B_k \ -‚àáf(x_k)
            # Step 2.: Find stepsize Œ±_k such that
            # Œ±_k = arg min ‚àÇf(x_k + Œ±_k * p_k)/‚àÇŒ±
            Œ±_k = line_search(numeric_differentiation(Œ±->(f(x_k + Œ± * p_k)), 10e-10))
            # Step 3.
            s_k = Œ±_k * p_k
            x_k_prime = x_k + s_k
            # Step 4.
            y_k = ‚àáf(x_k_prime) - ‚àáf(x_k)
            # Step 5.
            B_k += (y_k * y_k') / (y_k' * s_k) +
              - (B_k * s_k * s_k' * B_k) / (s_k' * B_k * s_k)
            x_k = x_k_prime
        end
        x_k
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|BFGS|}
  \label{listing:decay}
\end{listing}

Betrachten wir nun beispielsweise die Funktion $f(x) = \frac{x^5}{5000} + \frac{21 x^4}{4000} + \frac{17 x^3}{375} + \frac{293 x^2}{1000} + \frac{521 x}{1000}$ mit $\nabla f(x) = \frac{x^4}{1000} + \frac{21x^3}{1000} + \frac{17 x^2}{125} + \frac{293 x}{500} + \frac{521}{1000}$ und f√ºhren mit ihr BFGS aus
\mintinline{Julia}|BFGS(f, ‚àáf, [0], 500, ‚àáf -> gradient_descent(‚àáf, 10e-10, 1, 1e-10, 1000), 10e-5)|,
erhalten wir nach zwei Iterationen ein lokales Minimum bei $x=-1.1408$.

Eine recht simple Optimierung der Implementierung ist in Schritt 1 m√∂glich. Hier wird aktuell der \mintinline{Julia}|\|-Operator\footnote{\url{https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/}} eingesetzt. Dies ist zwar eine valide L√∂sung, jedoch nicht besonders effizient. Stattdessen kann hier nach \cite{wiki:BFGS} die Sherman‚ÄìMorrison‚ÄìWoodbury Formel angewandt werden um die Inverse rekursiv zu beschreiben. Die Rekursionsvorschrift lautet:
$$
B_{k+1}^{-1} = B_k^{-1} + \frac{(\mathbf{s}_k^T \mathbf{y}_k + \mathbf{y}_k^T B_k^{-1} \mathbf{y}_k)(\mathbf{s}_k \mathbf{s}_k^T)}{(\mathbf{s}_k^T \mathbf{y}_k)^2} - \frac{B_k^{-1} \mathbf{y}_k \mathbf{s}_k^T + \mathbf{s}_k \mathbf{y}_k^T B_k^{-1}}{\mathbf{s}_k^T \mathbf{y}_k}.
$$
F√ºr die erste Iteration gilt $B_1 = I_n$, und daher auch $p_1 = -\nabla f(\mathbf{x}_k)$ bzw. $B_1^{-1} = I_n$.

Mit dem fertigen BFGS kann man nun \mintinline{Julia}|fit_linear_model| dahingehend erweitern/√§ndern, dass es intern BFGS nutzt. Au√üerdem √∂ffnet BFGS die T√ºr zu anderen Verfahren wie z.B. logistischer Regression.

\newpage

\appendix

\section{Performancemessung}\label{appendix:measure}

Das Laufzeitverhalten wurde mittels des built-in Macros \mintinline{julia}|@time| gemessen. Testsystem war ein Intel i7-4790k@3.8GHz unter Linux Mint 19. Auswertung der Ausgabe des Macros erfolgte mittels des Python Scripts in Listing \ref{listing:measure}. Die Tabellenwerte ergeben sich als arithmetisches Mittel von 100 Aufrufen der Funktion \mintinline{julia}|fit_linear_model|.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg, linenos]{Python}
    from statistics import mean
    import re
    
    """Regex to capture different components
    Examples:
      0.000103 seconds (818 allocations: 87.328 KiB)
      0.000388 seconds (3.78 k allocations: 412.406 KiB)
      0.598357 seconds (2.02 M allocations: 102.555 MiB, 3.13% gc time)
    """
    RE = r"\s*(?P<time>\d+\.\d*) seconds \((?:(?P<allocs>\d+(?:\.\d*)?)"\
        r"(?: (?P<allocsuffix>M|k))?) allocations: (?:(?P<mem>\d+\.\d*)"\
        r"(?: (?P<memsuffix>(?:KiB|MiB)))?)(?:, (?P<gctime>\d+\.\d*)% gc time)?\)"
    
    MEMORY_FACTOR = {None: 1, "MiB": 1, "KiB": 1 / 1024}
    

    def get_and_parse():
        try:
            while line := input():
                match = re.match(RE, line)
                time = float(match["time"])
                mem = float(match["mem"]) * MEMORY_FACTOR[match["memsuffix"]]
                if (gc_time:=match["gctime"]) is not None:
                    gc = float(gc_time)
                else:
                    gc = None
                yield (time, mem, gc)
        except EOFError: return None
    

    time, memory, gc_time = zip(*(x for x in get_and_parse()))
    gc_time = list(filter(lambda x: x is not None, gc_time))
    print(
        f"Time: {mean(time):.5f} s, RAM: {mean(memory):.3f} MiB, "\
        f"GC-time: {mean(gc_time):.2f} % (got {len(gc_time)} gc values)")

  \end{minted}
  \caption{Python Script zur \mintinline{julia}|@time| Auswertung}
  \label{listing:measure}
\end{listing}
Das Script wurde f√ºr Python 3.8.0 geschrieben und ist auch nicht in √§lteren Versionen lauff√§hig(hierzu m√ºsste man die Assignment Expressions ersetzen). Der Code gestaltet sich etwas komplizierter, da \mintinline{Julia}|@time| je nach Anzahl der Allokationen ein verschiedenes Ausgabeformat w√§hlt. Daher seien spezielle Sprachfeatures und nicht-triviale Codepassagen hier kurz erl√§utert:

Hintereinanderstehende Strings werden in Python automatisch verkettet - \texttt{\textbackslash} erlaubt es lange Zeilen umzubrechen. Der \mintinline{Python}|:=| Operator f√ºhrt eine \emph{Assignment Expression}\footnote{\url{https://www.python.org/dev/peps/pep-0572/}} aus. Diese funktionieren √§hnlich einer Zuweisung in C oder auch ALGOL 68; in Kombination mit \mintinline{Python}|while| ergibt sich ein Konstrukt √§hnlich einem \mintinline{Rust}|while let Some(x) = ...| in Rust. Die Funktion \mintinline{Python}|get_and_parse| fungiert als Generator\footnote{\url{https://docs.python.org/3/howto/functional.html}} welcher √ºber stdin die Messwerte einliest, parset und als Dreiertupel zur√ºckgibt. F√ºr eine zweidimensionale Collection \texttt{c} in row-major order wandelt \mintinline{Python}|zip(*c)| diese in eine in column-major order um. Bei \texttt{RE} handelt es sich um eine Regular Expression\footnote{\url{https://docs.python.org/3/library/re.html}} welche in diesem Fall alle Eingabeformate unterscheiden und die einzelnen Komponenten automatisch extrahieren kann. Bei \mintinline{Python}|(x for x in get_and_parse())| in Zeile \texttt{31} handelt es sich um eine \emph{Generator Expression}\footnote{\url{https://www.python.org/dev/peps/pep-0289/}} welche √§hnlich zu einer List Comprehension in Python, Haskell, Erlang oder auch Julia funktioniert - jedoch im Effekt eine Art Lazy Evaluation realisiert. Diese Generator Expression wird hier nur ben√∂tigt um das Entpacken mittels \texttt{*} zu erm√∂glichen. Die Konvertierung des Generators zu einer Liste in Zeile 32 ist leider n√∂tig (sofern man keine eigene Funktion schreibt, welche gleichzeitig die L√§nge bestimmt und das Mittel berechnet) da der Generator beim Aufruf von \mintinline{Python}|len| oder \mintinline{Python}|mean| sonst verbraucht w√ºrde.
Die Nutzung erfolgt dann beispielsweise mit \mintinline{Bash}{$ julia Tests.jl | python3.8 measure.py}.

\bibliographystyle{alphadin}
\bibliography{Quellen}

\end{document}