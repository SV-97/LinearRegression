\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[german]{babel} % prefer english over german
\usepackage{multicol}
\usepackage{tikz}
\usetikzlibrary{angles,arrows,babel,calc,patterns,quotes}

\usepackage{graphicx}
\graphicspath{ {./img/} }

\usepackage{minted}
\usepackage{xcolor}
\usemintedstyle{manni}

\usepackage{eurosym}
\usepackage{amstext}

\usepackage{booktabs}

\usepackage{amssymb, amsmath, amsthm, amsfonts}

\usepackage{ulem} % allows striking out text among other things

\usepackage{fontspec}

\usepackage{newunicodechar}

\newunicodechar{ğ°}{$\textbf{w}$}
\newunicodechar{ğ±}{$\textbf{x}$}
\newunicodechar{â‚™}{${}_n$}
\newunicodechar{ğ—}{$\textbf{X}$}
\newunicodechar{â‚–}{${}_k$}
\newunicodechar{âˆ‡}{$\nabla$}

%\usepackage[santa]{realhats}

\setmonofont[
  Mapping=tex-text,
  Scale=0.90,
  UprightFont=*-Regular,
  BoldFont=*-Bold,
  ]{Fira Code}
%\setmonofont[Mapping=tex-text, Scale=0.90,]{Droid Sans Mono}

\theoremstyle{plain} %Text ist Kursiv
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Korollar}

\theoremstyle{definition} %Text ist \"upright"
\newtheorem{remark}[theorem]{Bemerkung}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Beispiel}
\newtheorem{algo}[theorem]{Algorithm}
\newtheorem{problem}[theorem]{Problem}
\let\proof\undefined
\newtheorem{proof}[theorem]{Beweis}
\newtheorem{theo}[theorem]{Satz}
\newtheorem{anno}[theorem]{Anmerkung}
\newtheorem{solution}[theorem]{LÃ¶sung}

% Colors
\definecolor{bg}{rgb}{0.95,0.95,0.95}

\newcommand{\sfloor}[1]{\left\lfloor #1 \right\rfloor} % scaling floor function
\newcommand{\sceil}[1]{\left\lceil #1 \right\rceil} % scaling ceil function
\newcommand{\floor}[1]{\lfloor #1 \rfloor} % floor function
\newcommand{\ceil}[1]{\lceil #1 \rceil} % ceil function
\newcommand{\specialset}[1]{\rm I\!#1} % render sets like R and N fancy
\newcommand{\abs}[1]{\left\lVert#1\right\rVert} % Absolute value of #1
\newcommand{\unit}[1]{\hat{#1}} % unit vector

\title{ Mehrdimensionales Datenfitting mit linearer Regression }

\rhead{\includegraphics[width=1.5cm]{FHWS}}
\lhead{}

\author{
  Stefan Volz\\
  FakultÃ¤t fÃ¼r angewandte Natur- und Geisteswissenschaften\\
  Hochschule fÃ¼r angewandte Wissenschaften WÃ¼rzburg-Schweinfurt\\
  Studiengang Technomathematik\\
  Matrikelnummer: 3519001\\
  \texttt{stefan.volz@student.fhws.de}\\
}

\date{\today, Wintersemester 2019}

%\renewcommand{\headeright}{Studienarbeit}
%\renewcommand{\undertitle}{Studienarbeit}

\begin{document}

\begin{center}
  \includegraphics[width=0.5\textwidth]{FHWS}  
\end{center}

\maketitle

\begin{abstract}
  In vielen Anwendungen ist es nÃ¶tig/vorteilhaft aus Messdaten ein mathematisches Modell zu entwickeln, welches mÃ¶glichst Messungenauigkeiten ausgleicht bzw. Vorhersagen zulÃ¤sst. Ziel der Arbeit ist die Implementierung von linearer Regression. Hierbei soll mittels Gradientenabstieg eine Fehlerminimierung des Modells im Bezug auf gegebene Messdaten durchgefÃ¼hrt werden und anschlieÃŸend am Beispiel von BFGS ein Ausblick auf komplexere Optimierungsverfahren gegeben werden. Die Implementierung erfolgt in Julia.
\end{abstract}

\tableofcontents
\newpage

\section{Konventionen und Generelles}
\subsection{Wahl der Programmiersprache und AbhÃ¤ngigkeiten}
Die Implementierung erfolgt in Julia\footnote{\url{https://julialang.org/}}. Julia ist eine hochperformante, stark und dynamisch typisierte, Ã¼berwiegend imperative Programmiersprache mit Fokus auf wissenschaftlichem Rechnen; ist jedoch im Gegensatz zu z.B. MATLAB als General Purpose Sprache zu verstehen. Die Arbeit benutzt Julia in Version 1.2.0. Die AbhÃ¤ngigkeiten beschrÃ¤nken sich auf das \texttt{Plots} Package\footnote{\url{https://docs.juliaplots.org/}} - jedoch ist die eigentliche Logik abhÃ¤ngigkeitsfrei.

Die Wahl der Sprache fiel auf Julia, da es nativ eine sehr gute UnterstÃ¼tzung fÃ¼r Matrizen mitbringt was fÃ¼r die Implementierung als sehr vorteilhaft angesehen wird. AuÃŸerdem erlaubt der gute Unicode-Support es, Identifier so zu wÃ¤hlen, dass diese nah an der Fachliteratur sind. Desweiteren ist die immense Performancesteigerung gegenÃ¼ber beispielsweise Python ein groÃŸes Plus. Syntaktisch und semantisch sollte Julia fÃ¼r Leser, die eine andere dynamische Hochsprache (z.B. Python, Matlab, Ruby) beherrschen kein Problem sein - spezielle Sprachfeatures werden i.d.R. in FuÃŸnoten kurz erklÃ¤rt.

\subsection{Quellcode}
Beim Code wird darauf geachtet, die Typannotationen\footnote{\url{https://docs.julialang.org/en/v1/manual/types/}} von Julia zu nutzen, da diese zum einfacheren VerstÃ¤ndnis des Codes beitragen und auÃŸerdem der Performance zutrÃ¤glich sind.
Identifier werden grÃ¶ÃŸtenteils so gewÃ¤hlt, dass sie sich mit \cite{Bishop} decken - teils werden jedoch auch Bezeichner aus \cite{Lippe} Ã¼bernommen. Der Code wird unter \url{https://github.com/SV-97/LinearRegression} gehostet.

\subsection{Text dieser Arbeit}
Im Text der Arbeit werden - in Anlehnung an \cite{Bishop} - folgende Konventionen genutzt:

\begin{tabular}{llc}
  \toprule
  Typ & Beschreibung & Beispiel \\
  \midrule
  vektorielle GrÃ¶ÃŸen & fettgedruckte Kleinbuchstaben & $\mathbf{w}$ \\
  einzelne Elemente eines Vektors & indizierte Kleinbuchstaben & $w_j$ \\
  Matrizen und Mengen & GroÃŸbuchstaben & $A$ \\
  Hyperparameter des Modells & griechische Kleinbuchstaben & $\gamma$ \\
  sonstige Parameter & lateinische Kleinbuchstaben & $x$ \\
  Code listings und Quellcode-Referenzen & monospace font & \mintinline{julia}|code| \\
\end{tabular}

Einzelne Indizes an Matrixen wie z.B. $A_j$ sind als Zeilenindizes zu verstehen, sodass $A_j$ die j-te Zeile von $A$ ist.
In einigen FÃ¤llen wird zwecks Konsistenzwahrung mit \cite{Bishop} oder der zum jeweiligen Thema gehÃ¶rigen Literatur von diesen Konventionen abgewichen.
FÃ¼r eine Matrix $A$ steht $A^T$ fÃ¼r die Transponierte. Die IdentitÃ¤tsmatrix zu $\mathbb{R}^{n \times n}$ wird geschrieben als $I_n$.

\subsection{Variablenbezeichner}

Einige der wichtigsten Bezeichner sind hier aufgefÃ¼hrt:

\begin{tabular}{cl}
  \toprule
  Bezeichner & Beschreibung\\
  \midrule
  $d$ & Dimension eines Eingabevektors\\
  $k$ & Dimension eines Zielwertsvektors\\
  $M$ & Anzahl der Modellparameter\\
  $N$ & Anzahl der TrainingsdatensÃ¤tze\\
  $X$ & Trainingseingabematrix\\
  $T/\mathbf{t}$ & Trainingszielmatrix/Trainingszielvektor\\
  $\mathbf{w}$ & Modellparameter\\
\end{tabular}


\section{Grundlegende Implementierung}
\subsection{Problemformulierung}
Seien $d,k,M,N \in \mathbb{N}$ mit Messdaten $X \in \mathbb{R}^{d \times N}$ und zugehÃ¶rigen Zielwerten $T \in \mathbb{R}^{k \times N}$ gegeben. Gesucht werden die Parameter $\mathbf{w}$ eines Modells $y(\mathbf{w}, \mathbf{x})$ mit $y \in \mathbb{R}^M \times \mathbb{R}^d \rightarrow \mathbb{R}^{k}$ welche das Minimierungsproblem
$$
    \min_{\mathbf{w} \in \mathbb{R}^M}\sum_{i=1}^N E(y(\mathbf{w}, X_{i}), T_{i}),
$$
im Bezug auf eine Fehlerfunktion $E: \mathbb{R}^k \times \mathbb{R}^k \rightarrow \mathbb{R}$ lÃ¶sen.

Wir betrachten zunÃ¤chst nur Probleme fÃ¼r die $k=1$ gilt und bezeichnen daher die Zielwerte mit $\mathbf{t}$.

\subsection{Lineare Regression}
\subsubsection{Mathematische Grundlagen}
Bei linearer Regression handelt es sich um eine Methode des Ã¼berwachten Lernens.
\begin{definition}
  Lineare Regressions Modelle sind Modelle, welche sich im Bezug auf ihre Modellparameter linear verhalten\cite[S. 137f]{Bishop}. Sie stellen Funktionen der Form $y: \mathbb{R}^M \times \mathbb{R}^d \rightarrow \mathbb{R}^k, (\mathbf{w}, \mathbf{x}) \mapsto y(\mathbf{w}, \mathbf{x})$ dar. Die Anzahl der Modellparameter ist gegeben durch $M \in \mathbb{N}$, die Anzahl an EingangsgrÃ¶ÃŸen durch $d \in \mathbb{N}$ und die der ZielgrÃ¶ÃŸen durch $k \in \mathbb{N}$.
\end{definition}
\begin{anno}
  Dies bedeutet nicht, dass sie auch zwingend linear im Bezug auf die Eingangsvariablen sein mÃ¼ssen.
\end{anno}

Das einfachste lineare Regressions Modell ist eine Linearkombination der Eingangsvariablen 
$$
  y(\mathbf{w}, \mathbf{x}) = w_0 + w_1x_1 + w_2x_2 + \hdots + w_Dx_D,
$$
diese spiegeln jedoch oftmals nicht die zugrunde-liegende Verteilung der realen Messwerte wider, und limitieren ein Modell mit $d$ Eingangsvariablen auf $d+1$ Modellparameter. Daher werden Basisfunktionen eingefÃ¼hrt und Lineare Regressions Modelle als Linearkombination dieser gebildet.
\begin{definition}
  Eine Funktion $\Phi_j: \mathbb{R}^d \rightarrow \mathbb{R}^k, \mathbf{x} \mapsto \Phi_j(\mathbf{x})$ bezeichnen wir als Basisfunktion.
\end{definition}
\begin{anno}
  Im Code werden Basisfunktionen als Funktionen $\Phi: \mathbb{N} \times \mathbb{R}^d \rightarrow \mathbb{R}^k, (j, \mathbf{x}) \mapsto \Phi(j, \mathbf{x})$ implementiert.
\end{anno}

Mit diesen Basisfunktionen ergibt sich als Modellgleichung
$$
  y(\mathbf{w}, \mathbf{x}) = w_0 + \sum_{j=1}^{M-1}w_j\Phi_j(\mathbf{x}),
$$
wobei der Parameter $w_0$ auch als Bias-Parameter bezeichnet wird, da er einen festen Offset der Daten ermÃ¶glicht. Im Code betrachten wir diesen Bias-Parameter als ``normalen'' Parameter und wÃ¤hlen als kleinsten Index in $\mathbf{w}$ Eins. Ein eingangsvariablenunabhÃ¤ngiger Offset ist leicht durch eine angepasste Definition der Basisfunktion erreichbar:
\[ \Phi: (j, \mathbf{x}) \mapsto
 \left\{
  \begin{array}{ll}
    1,& j=1, \\
    \Phi_j(\mathbf{x}), & sonst. \\  
  \end{array}
\right. \]

Damit vereinfacht sich die Darstellung der Modellgleichung zu
\begin{align}
  y(\mathbf{w}, \mathbf{x}) = \sum_{j=1}^{M}w_j\Phi(j, \mathbf{x}). \label{y}
\end{align}

\subsubsection{Implementierung}
Auf Basis dieser Formulierungen kÃ¶nnen wir mit der Implementierung beginnen.
Hierzu definieren wir uns zunÃ¤chst eine Funktion \texttt{$\Sigma$} um alle im Code vorkommenden Summen zu abzudecken.

\begin{listing}[H] % maybe use [!ht] instead?
    \begin{minted}[bgcolor=bg]{julia}
        "Sum from k=`from` to `to` of `a(k)`"
        Î£(from::Integer, to::Integer, a::Function, zero = 0) =
          mapreduce(a, (+), from:to; init = zero)
    \end{minted}
    \caption{Funktion \mintinline{julia}|Î£|}
\end{listing}

Die Funktion ist hierbei eine Implementierung von $\sum_{k=\text{from}}^\text{to}a(k)$. Bei \texttt{mapreduce} handelt es sich um eine eingebaute Funktion welche (hier) erst \texttt{a} Ã¼ber eine Sequenz mappt und anschlieÃŸend diese Sequenz mittels \texttt{(+)} reduziert/faltet. Dabei ist \texttt{(+)} der eingebaute Additionsoperator. Der optionale Parameter \texttt{zero} erlaubt es die Funktion auch fÃ¼r nicht-skalare Summen(bzw. jegliche Typen fÃ¼r die eine Implementierung zu \texttt{+} existiert) zu nutzen.

\begin{listing}[H]
    \begin{minted}[bgcolor=bg]{Julia}
      """Linear Regression
      # Args:
          ğ°: Parameters
          Î¦(j, ğ±): Basis function of type (Int, Vector{T}) -> T
          ğ±: Input vector
      """
      function y(
        ğ°::Vector{<:Number},
        Î¦::(T where T <: Function),
        ğ±::Vector{<:Number})::Number
          Î£(1, size(ğ°)[1], j->ğ°[j] * Î¦(j, ğ±))
      end
    \end{minted}
    \caption{Funktion \mintinline{julia}|y|}
    \label{listing:y}
\end{listing}

Diese Implementierung der Funktion \texttt{y} passt 1:1 zur mathematischen Formulierung in Gleichung \ref{y}\footnote{Die in Listing \ref{listing:y} genutzte Schreibweise \mintinline{julia}|Vector{<:Number}| bedeutet \emph{Vektor eines Typen T, wobei T ein Subtyp des abstrakten Typs Number ist}. Diese hat gegenÃ¼ber \mintinline{julia}|Vector{Number}| den Vorteil, dass sie gewisse Optimierungen ermÃ¶glicht(Im Detail erlaubt \mintinline{Julia}|<:| Julia mit unboxed Werten zu arbeiten).}.

\subsection{Die Fehlerfunktion}

Als nÃ¤chstes benÃ¶tigen wir eine MÃ¶glichkeit um den Fehler des Systems zu ermitteln - sodass wir diesen im nÃ¤chsten Schritt minimieren kÃ¶nnen. Die genutzte Fehlerfunktion ist die des quadratischen Fehlers. Nach \cite[S. 140f]{Bishop} ergibt sich die Fehlerfunktion
\begin{align}
    E_D := \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, \mathbf{x}))^2.
\end{align}

Mit dieser Definition kÃ¶nnen wir nun unser Minimierungsproblem wie folgt definieren:
$$
  \min_{\mathbf{w} \in \mathbb{R}^M} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, X_n))^2.
$$
Im nÃ¤chsten Schritt werden wir ein Verfahren implementieren, das diese Minimierung durchfÃ¼hrt.

\subsection{Gradientenabstiegsverfahren}

\subsubsection{Mathematische Grundlagen}

Das Gradientenabstiegsverfahren ist ein numerisches Verfahren mit dem sich allgemeine Optimierungsprobleme lÃ¶sen lassen. Beim Gradientenabstiegsverfahren bestimmen wir den Gradienten von $E_D$ im Bezug auf die Modellparameter $\mathbf{w}$ - diesen Gradienten bezeichnen wir mit $\nabla_\mathbf{w} E_D$. Hierzu bestimmen wir zunÃ¤chst die partielle Ableitungen von $E_D$ nach allen $w_k$ aus $\mathbf{w}$.
$$
  \frac{\partial E_D}{\partial \mathbf{w}_k} = \frac{\partial}{\partial \mathbf{w}_k} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, \mathbf{x}))^2 = - \sum_{n=1}^N \Phi(k, X_n) \cdot (\mathbf{t}_n - y(\mathbf{w}, \Phi, X_n))
$$
Der Gradient ist dann
$$
  \nabla_\mathbf{w} E_D
    = \left( \begin{array}{c}
      \frac{\partial E_D}{\partial \mathbf{w_1}}\\
      \vdots\\
      \frac{\partial E_D}{\partial \mathbf{w_M}}\\
      \end{array} \right).
$$

Um diesen Gradienten zu implementieren, beginnen wir mit der Implementierung der partiellen Ableitung:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Derivative of E_D with respect to ğ°â‚–
    # Args:
        Î¦(k, ğ±â‚™): Basis function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        k: Index for ğ°â‚– in respect to which the derivative is taken
        ğ°: Parameters
    """
    function âˆ‚E_Dâˆ‚w_k(
      Î¦::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      ğ°::Vector{<:Number},
      k::Integer)::Number
        N = size(t)[1]
        - Î£(1, N, n->Î¦(k, ğ—[n, :]) * (t[n] - y(ğ°, Î¦, ğ—[n,:])))
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|âˆ‚E_Dâˆ‚w_k|}
  \label{listing:partial}
\end{listing}

\subsubsection{Einzeliteration des Gradientenabstiegs}

Hiermit kÃ¶nnen wir eine Iteration des Gradientenabstiegsalgorithmus wie folgt implementieren.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """One iteration of the gradient descent algorithm
    # Args:
        âˆ‚E_Dâˆ‚w_k: Partial derivative of error function with respect to
            the k-th parameter
        ğ—: Column vector of inputs ğ±â‚™ where ğ±â‚™ is an input vector to the
            error function
        t: corresponding target values for each ğ±â‚™
        ğ°: Parameters
        Î·: Learning rate
    """
    function gradient_descent_iteration(
      âˆ‚E_Dâˆ‚w_k::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      ğ°::Vector{<:Number},
      Î·::Number)::Vector{<:Number}
        M = size(ğ°)[1]
        âˆ‡ğ° = zero(ğ°)
        for j = 1:M
            âˆ‚E_Dâˆ‚w_jk(k) = âˆ‚E_Dâˆ‚w_k(ğ—, t, ğ°, k)
            âˆ‡ğ° += collect(map(âˆ‚E_Dâˆ‚w_jk, 1:M))
        end
        ğ° - Î· * âˆ‡ğ°
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent_iteration|}
  \label{listing:gd_iteration}
\end{listing}

Innerhalb der Funktion iterieren wir Ã¼ber alle Indizes $j$, bilden die partielle Ableitung nach $\mathbf{w}_k$\footnote{Achtung: Die hier genutzte Funktion ist nicht die des globalen Scopes, sondern ein Parameter der Funktion.} und berechnen ihren Wert fÃ¼r alle Komponenten des Ergebnisvektors. Der Gradient ist dann die Summe all dieser Vektoren. In der letzten Zeile der Funktion machen wir einen ''Schritt'' in Richtung des Gradienten - steigen auf der Fehlerkurve also ab. Die Schrittweite wird hierbei durch den Hyperparameter $\eta$ gesteuert. Dieser als Lernrate bezeichnete Parameter steuert im Grunde genommen die Konvergenzgeschwindigkeits des Gradientenabstiegsverfahrens.

\subsubsection{Hauptfunktion}

Auf Basis dieser Funktion kÃ¶nnen wir nun den Rest des Algorithmus in der Funktion \mintinline{julia}|gradient_descent| umsetzen.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Minimize function E_D(ğ—, t, ğ°)
    # Args:
        âˆ‚E_Dâˆ‚w_k: Partial derivative of error function with respect to
            the k-th parameter
        ğ—: Column vector of inputs ğ±â‚™ where ğ±â‚™ is an input vector to the
            error function
        t: corresponding target values for each ğ±â‚™
        ğ°: Initial parameters - usually `randn(M)`
        Î·: Learning rate
        M: Number of model parameters
        iters: Number of iterations
    """
    function gradient_descent(
      âˆ‚E_Dâˆ‚w_k::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      Î·::Number,
      M::Integer,
      iters::Integer,
      ğ°::Vector{<:Number})::Vector{<:Number}
        âˆ‡ğ° = zero(ğ°)
        for i = 1:iters
            ğ° = gradient_descent_iteration(âˆ‚E_Dâˆ‚w_k, ğ—, t, ğ°, Î·)
        end
        ğ°
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent|}
  \label{listing:gd}
\end{listing}

Diese Funktion ruft \mintinline{julia}|iters|-mal die Hilsfunktion \mintinline{julia}|gradient_descent_iteration| auf und updated die Parameter mit dem Ergebnis dieser Aufrufe. Nach Ende der Optimierung gibt sie die als optimal befundenen Werte der Parameter zurÃ¼ck. 
\newpage
Der Aufruf von \mintinline{julia}|gradient_descent| erfolgt aus der Funktion \mintinline{julia}|fit_linear_model| heraus.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Find regression model 
    # Args:
        Î¦: Basis Function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        Î·: learning rate with which to train
        M: Number of model parameters
        iters: Number of iterations
        optimizer: Parameter to select optimizer that's used
    # Fails:
        On unknown optimizers or error inside the optimizer
    """
    function fit_linear_model(
      Î¦::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      Î·::Number,
      M::Integer,
      iters::Integer,
      optimizer = :gradient_descent)::Tuple{Function,Number}
        if optimizer == :gradient_descent
            ğ° = gradient_descent(
              (ğ—, t, ğ°, k)->âˆ‚E_Dâˆ‚w_k(Î¦, ğ—, t, ğ°, k),
              ğ—, t, Î·, M, iters, randn(M), Îµ, Î³)
            residual_error = E_D(Î¦, ğ—, t, ğ°)
            (ğ±->y(ğ°, Î¦, ğ±), residual_error)
        else
            error("Invalid optimizer")
        end
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|fit_linear_model|}
  \label{listing:gd}
\end{listing}

Diese Funktion stellt im Grunde genommen nur einen Treiber fÃ¼r den Optimizer da. Sie initialisiert die Modellparameter zu Beginn mit einem Vektor aus normalverteilten Zufallszahlen\cite{Lippe} aus dem Intervall $[-1, 1]$. Nach der Optimierung gibt sie das vollendete Modell als Closure\footnote{Eine Closure ist eine anonyme Funktion welche intern eine Referenz auf ihren Erstellungskontext hÃ¤lt. Hier wird sie eingesetzt um \mintinline{julia}|y| mit \mintinline{julia}|ğ°| und \mintinline{julia}|Î¦| partiell zu evaluieren.} zurÃ¼ck, was dem die Funktion Aufrufenden ermÃ¶glicht, Modellaussagen in AbhÃ¤ngigkeit eines Eingangsvektors zu erhalten. AuÃŸerdem bestimmt sie den Restfehler des Modells und gibt auch diesen zurÃ¼ck. Der Parameter \mintinline{julia}|optimizer| ist bisher noch nicht in Benutzung, da nur ein Optimizer implementiert ist\footnote{\mintinline{julia}|:abc| ist ein Symbol-Literal. Diese Symbole sind vergleichbar mit denen in Ruby und Scheme oder auch Atomen in Erlang und Prolog. (siehe \url{https://docs.julialang.org/en/v1/manual/metaprogramming/})}.

\subsubsection{Abbruchkriterium}

Die Grundimplementierung wird mit einem einfachen Abbruchkriterium abgeschlossen. Hierbei wird zu jeder Iteration geprÃ¼ft, ob die Norm der Differenz der Parametervektoren von zwei aufeinanderfolgenden Iterationen kleiner als ein neuer Hyperparameter $\varepsilon$ ist - in Formeln ausgedrÃ¼ckt: es wird geprÃ¼ft ob $||\mathbf{w} - \mathbf{w}'||_2 < \varepsilon$ gilt.
AuÃŸerdem wird geprÃ¼ft ob einer der Parameter zu $\pm\infty$ divergiert (und das Verfahren somit ''fehlgeschlagen'') ist oder durch einen Rechenfehler ein \mintinline{julia}|NaN|\footnote{\emph{Not a Number} - spezieller Wert von IEEE floats} in $\mathbf{w}$ aufgetaucht ist. In all diesen FÃ¤llen wird der Algorithmus vorzeitig abgebrochen. Sofern kein Fehler vorliegt werden die Modellparameter zurÃ¼ckgegeben\footnote{Der Punkt im Funktionsaufruf in Listing \ref{listing:simplebreak} sorgt dafÃ¼r, dass die Funktion vektorisiert/\emph{pointwise} aufgerufen wird (siehe \url{https://docs.julialang.org/en/v1/manual/functions/}).}. AuÃŸerdem Ã¤ndert sich der RÃ¼ckgabewert der Funktion diesbezÃ¼glich, dass sie nun zurÃ¼ckgibt wieviele Iterationen tatsÃ¤chlich durchlaufen wurden.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia} 
    """Minimize function E_D(ğ—, t, ğ°)
    # Args:
        âˆ‚E_Dâˆ‚w_k: Partial derivative of error function with respect to
            the k-th parameter
        ğ—: Column vector of inputs ğ±â‚™ where ğ±â‚™ is an input vector to the
            error function
        t: corresponding target values for each ğ±â‚™
        ğ°: Initial parameters - usually `randn(M)`
        Î·: Learning rate
        M: Number of model parameters
        iters: Number of iterations
        Îµ: Gradient descent stops once the difference between two iterations
            (ğ° and ğ°') is less than Îµ

    # Fails:
        Fails on encountering NaN in computation or on Divergence to Inf
    """
    function gradient_descent(
      âˆ‚E_Dâˆ‚w_k::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      Î·::Number,
      M::Integer,
      iters::Integer,
      ğ°::Vector{<:Number},
      Îµ = 10e-12::Number)::Tuple{Vector{<:Number},Integer}
        did_iters = 0
        for i = 1:iters
            did_iters += 1
            ğ°_old = ğ°
            ğ° = gradient_descent_iteration(âˆ‚E_Dâˆ‚w_k, ğ—, t, ğ°, Î·, âˆ‡ğ°, Î³)
            if any(isnan.(ğ°))
              error("Encountered NaN") 
            end
            if any(isinf.(ğ°))
                error("Divergence in calculation")
            end
            if norm(ğ°_old - ğ°) < Îµ
                break
            end
        end
        (ğ°, did_iters)
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent| mit einfachem Abbruchkriterium}
  \label{listing:simplebreak}
\end{listing}

FÃ¼r den Parameter $\varepsilon$ wird eine arbitrÃ¤r gewÃ¤hlte Standartbelegung von $10\cdot10^{-12}$ gesetzt. Ein weiteres denkbares und oft genutztes Abbruchkriterium ist die ÃœberprÃ¼fung, ob die Norm des Gradienten ungefÃ¤hr Null ist.

\section{Fortgeschrittene Features}
\subsection{Momentum Verfahren}
Das Momentum Verfahren ist eine Adaption des Gradientenabstiegs, welche die Konvergenzgeschwindigkeit erhÃ¶hen soll. Das Ziel ist es, auf flachen Bereichen der Fehlerkurve die Abstiegsgeschwindigkeit zu erhÃ¶hen und sie in steilen Passagen zu verringern. Das Verfahren lÃ¤sst sich als ein Ball der eine Kurve hinabrollt visualisieren - dieser verhÃ¤lt sich bei Ã„nderungen der Kurve mit einer gewissen TrÃ¤gheit.
Um eine solche TrÃ¤gheit zu realisieren wird ein Momentum-Term hinzugefÃ¼gt. Dieser Term ist das Produkt des Gradienten der vorhergehenden Iteration und eines neuen Hyperparameters $\gamma \in [0,1)$ - dem TrÃ¤gheitsfaktor. Der Gradient $\nabla_\mathbf{w}\hat{E_D}$ in jeder Iteration ergibt sich dann aus dem eigentlichen Gradienten dieser Iteration $\nabla_\mathbf{w} E_D'$ sowie dem der vorhergehenden Iteration $\nabla_\mathbf{w} E_D$ multipliziert mit dem Momentum-Faktor $\gamma$.
$$
  \nabla_\mathbf{w} \hat{E}_D = \nabla_\mathbf{w} E_D' + \gamma \nabla_\mathbf{w} E_D
$$
Zur Implementierung mÃ¼ssen lediglich $\gamma$ und $\nabla_\mathbf{w} E_D$(im Code \mintinline{julia}|âˆ‡ğ°_prior|) als neue Parameter hinzugefÃ¼gt werden und die RÃ¼ckgabe so angepasst, dass in jeder Iteration ein 2-Tupel aus neuem Parametervektor und aktuellem Gradienten zurÃ¼ckgegeben wird. Dementsprechend mÃ¼ssen auch die call sites in \mintinline{julia}|gradient_descent| sowie \mintinline{julia}|fit_linear_model| angepasst werden. Da die Ã„nderungen an den call sites trivial sind ist hier nur \mintinline{julia}|gradient_descent_iteration| aufgefÃ¼hrt.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """One iteration of the gradient descent algorithm
    # Args:
        âˆ‚E_Dâˆ‚w_k: Partial derivative of error function with respect to
            the k-th parameter
        ğ—: Column vector of inputs ğ±â‚™ where ğ±â‚™ is an input vector to the
            error function
        t: corresponding target values for each ğ±â‚™
        ğ°: Parameters
        Î·: Learning rate
        âˆ‡ğ°_prior: Gradient of parameters from prior iteration
        Î³: Momentum factor
    """
    function gradient_descent_iteration(
      âˆ‚E_Dâˆ‚w_k::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      ğ°::Vector{<:Number},
      Î·::Number,
      âˆ‡ğ°_prior::Vector{<:Number},
      Î³::Number)::Tuple{Vector{<:Number},Vector{<:Number}}
        M = size(ğ°)[1]
        âˆ‡ğ° = Î³ * âˆ‡ğ°_prior
        for j = 1:M
            âˆ‚E_Dâˆ‚w_jk(k) = âˆ‚E_Dâˆ‚w_k(ğ—, t, ğ°, k)
            âˆ‡ğ° += collect(map(âˆ‚E_Dâˆ‚w_jk, 1:M))
        end
        (ğ° - Î· * âˆ‡ğ°, âˆ‡ğ°)
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent_iteration| mit Momentum Verfahren}
  \label{listing:momentum}
\end{listing}

Nach \cite[S. 110]{Lippe} wird $\gamma$ mit einem Wert von $0.9$ vorbelegt. Die wohl grÃ¶ÃŸte Problematik dieses Verfahrens ist, dass der Fall auftreten kann das der Momentum-Term betragsmÃ¤ÃŸig grÃ¶ÃŸer als der aktuelle Gradient ist, jedoch das umgekehrte Vorzeichen besitzt. In diesem Fall wÃ¼rde sich der Fehler des Systems vergrÃ¶ÃŸern. Aufgrund dessen kann hier keine Konvergenz garantiert werden.
Ein kurzer Test\footnote{Die Funktion mit der getestet wurde ist $x \mapsto x^2+\theta_x$, wobei $\theta_x$ ein Wert aus einem normalverteilten Rauschen von $-3$ bis $+3$ ist.} (mit konstanter Lernrate und \texttt{Îµ=10e-12} mit nur wenigen Datenpunkten zeigt folgende Daten\footnote{Details zur Messung in Anhang \ref{appendix:measure}. Es ist zu beachten, dass der insgesamt allokierte Speicher dargestellt ist.}:

\begin{center}
  \begin{tabular}{cccccc}
    \toprule
    $\gamma$ & k bei Abbruch & Restfehler bei Abbruch & Laufzeit & Gesamt allokierter & Garbage Collector\\
    &  nach k Iterationen & des Algorithmus & (in Sekunden) & Speicher (in MiB) & Zeitanteil (in \%) \\
    \midrule
    $0.0$ & $50544$ & $6.701991676725787$ & $0.80471$ & $890.111$ & $9.37$ \\
    $0.5$ & $28837$ & $6.701991676725787$ & $0.43627$ & $463.782$ & $9.46$ \\
    $0.9$ & $5635$ & $6.701991676725783$ & $0.07825$ & $99.488$ & $8.39$ \\
  \end{tabular}
\end{center}

Also gibt es durchaus FÃ¤lle, in denen durch dieses Verfahren eine enorme Steigerung bei der Konvergenzgeschwindigkeit erzielt wird. Jedoch sehen die VerlÃ¤ufe der Kurven von Restfehler und Gradient wie folgt aus:

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_0_Error_10e-12_Crop}
  \caption{Beispielfit mit $\gamma=0$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_5_Error_10e-12_Crop}
  \caption{Beispielfit mit $\gamma=0.5$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_9_Error_10e-12_Crop}
  \caption{Beispielfit mit $\gamma=0.9$}
\end{figure}

Es ist klar zu sehen, dass der oben genannte 'worst case' im Fall $\gamma=0.9$ eingetreten ist. Das vermeintlich bessere Konvergenzverhalten lag daran, dass ein sehr geringes $\varepsilon$ gewÃ¤hlt wurde. ErhÃ¶hen wir $\varepsilon$ auf beispielsweise \texttt{10e-3}, dann ergeben sich die folgenden Werte\footnote{Die GC Werte sind gestrichen, da sie sich nicht fÃ¼r alle TestdurchlÃ¤ufe bestimmen  lieÃŸen (\mintinline{Julia}|@time| liefert bei zu kurzen DurchlÃ¤ufen nicht zwingend alle Werte - evtl. liefert es keinen Wert falls wÃ¤hrend des Messvorgangs keine GC-Iteration vorlag. Die angegebenen Werte sind das Mittel aus drei Iterationen in denen ein GC-Wert vorlag.)}:

\begin{center}
  \begin{tabular}{cccccc}
    \toprule
    $\gamma$ & k bei Abbruch & Restfehler bei Abbruch  & Laufzeit & Gesamt allokierter & Garbage Collector\\
    &  nach k Iterationen & des Algorithmus & (in Sekunden) & Speicher (in MiB) & Zeitanteil (in \%) \\
    \midrule
        $0.0$ & $24$ & $10.216203809068343$ & $0.00581$ & $1.398$ & \sout{$61.54$} \\
        $0.5$ & $14$ & $6.813835951850837$  & $0.00570$ & $1.232$ & \sout{$48.19$} \\
        $0.9$ & $29$ & $36.63725946510655$  & $0.00680$ & $1.438$ & \sout{$60.92$} \\
  \end{tabular}
\end{center}

beziehungsweise folgende Graphen:

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_0_Error_10e-3}
  \caption{Beispielfit mit $\gamma=0$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_5_Error_10e-3}
  \caption{Beispielfit mit $\gamma=0.5$}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Momentum_0_9_Error_10e-3}
  \caption{Beispielfit mit $\gamma=0.9$}
\end{figure}

Das Momentumverfahren wirkt sich hier also teils positiv und teils negativ aus - bei der Wahl der Parameter ist vorsicht geboten.

\subsection{Tichonow Regularisierung}
Eine weitere MÃ¶glichkeit der Verbesserung des Verfahrens ist die \emph{Tichonow Regularisierung}. Das Ziel dieses Verfahrens ist es, die StabilitÃ¤t des Modells zu verbessern. Dabei wird das Minimierungsproblem wie folgt neu formuliert:
$$
  \min_{\mathbf{w} \in \mathbb{R}^M} \frac{1}{2}\sum_{n=1}^{N}(\mathbf{t}_n - y(\mathbf{w}, X_n))^2 + \omega ||\mathbf{w}||^2_2.
$$
Es werden also zu groÃŸe Werte in $\mathbf{w}$ ''bestraft''. Hierbei ist $\omega$ ein neuer Hyperparameter welcher festlegt wie ''wichtig'' die Minimierung des Parametervektors ist. Die neue partielle Ableitung ist damit:
$$
  \frac{\partial E_{D, decay}}{\partial \mathbf{w}_k} = - \sum_{n=1}^N \Phi(k, X_n) \cdot (\mathbf{t}_n - y(\mathbf{w}, \Phi, X_n)) - \omega \mathbf{w}_k
$$

Die erforderlichen Ã„nderungen am Code sind das Durchschleifen des Parameters $\omega$ und die Anpassung der partielle Ableitung:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """Derivative of E_D with respect to ğ°â‚–
    # Args:
        Î¦(k, ğ±â‚™): Basis function
        ğ—: Set of inputs ğ±â‚™ where ğ±â‚™ is an input vector to Î¦
        t: corresponding target values for each ğ±â‚™
        ğ°: Parameters
        k: Index for ğ°â‚– in respect to which the derivative is taken
        Ï‰: Weight decay factor
    """
    function âˆ‚E_Dâˆ‚w_k(Î¦::Function,
      ğ—::Matrix{<:Number},
      t::Vector{<:Number},
      ğ°::Vector{<:Number},
      k::Integer,
      Ï‰::Real)::Number
        N = size(t)[1]
        - Î£(1, N, n->Î¦(k, ğ—[n, :]) * (t[n] - y(ğ°, Î¦, ğ—[n,:])) - Ï‰*ğ°[k])
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|âˆ‚E_Dâˆ‚w_k| mit Tichonow Regularisierung}
  \label{listing:decay}
\end{listing}

\subsection{Ausblick auf den Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno Algorithmus}

Der Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno - oder kurz BFGS - Algorithmus, ist ein Optimierungsverfahren aus der Gruppe der Quasi-Newton Verfahren. Nach \cite{Dai} ist BFGS der effizienteste Vertreter dieser Gruppe; so findet sich das Verfahren auch in vielen professionellen Softwaretoolboxes und Programmiersprachen wie z.B. R, Matlab oder auch SciPy wieder.
Ziel ist das lÃ¶sen des Optimierungsproblems $\min_{\mathbf{x} \in \mathbb{R}^n} f(\mathbf{x})$ mit $f: \mathbb{R}^n \rightarrow \mathbb{R}$.
Beginnend mit einem Startwert $\mathbf{x}_0$ und einer NÃ¤herung der Hesse Matrix $B_0 := I_n$ werden folgende Schritte abgearbeitet. Dabei konvergiert $\mathbf{x}_k$ gegen die LÃ¶sung des Problems.

\begin{enumerate}
  \item{ Bestimmen einer Abstiegsrichtung $\mathbf{p}_k$ durch lÃ¶sen des LGS $B_k \cdot \mathbf{p}_k = - \nabla f(\mathbf{x}_k)$. }
  \item{ Sei $g_k: \mathbb{R} \rightarrow \mathbb{R}$ definiert durch $\alpha \mapsto f(x_k + \alpha \cdot p_k)$, dann ist die Schrittweite $\alpha_k > 0$ gegeben durch $\alpha_k = \arg \min_{\alpha \in \mathbb{R}} \frac{\partial g_k}{\partial \alpha}$.\\Dieses Minimierungsproblem wird mittels eines Liniensuchverfahrens (in der Implementierung wird hier zwecks Einfachheit das Gradientenabstiegsverfahren gewÃ¤hlt - andere mÃ¶gliche Kandidaten wÃ¤ren z.B. Newton Verfahren oder das CG-Verfahren) gelÃ¶st - wobei nur ein lokales Minimum gesucht wird\cite{Dai}.}
  \item {Setzen von $\mathbf{s}_k = \alpha_k \cdot \mathbf{p}_k$ und $\mathbf{x}_{k+1} = \mathbf{x}_k + \mathbf{s}_k$.}
  \item {Berechnung von $\mathbf{y}_k = \nabla f(\mathbf{x}_{k+1}) - \nabla f(\mathbf{x}_k)$.}
  \item {Neue NÃ¤herung der Hesse Matrix $B$ nach der Rekursionsvorschrift $B_{k+1} = B_k + \frac{\mathbf{y}_k \mathbf{y}_k^T}{\mathbf{y}_k^T \mathbf{s}_k} - \frac{B_k \mathbf{s}_k \mathbf{s}_k^T B_k}{\mathbf{s}_k^T B_k \mathbf{s}_k}$ bestimmen.}
\end{enumerate}

Schritt 2 lÃ¤sst sich so visualisieren, dass man die durch die Funktion beschriebene Figur mit der von Gradient und y-Achse aufgespannten Ebene schneidet - und dann das der aktuellen Position nÃ¤heste lokale Minimum der dabei entstehenden Kurve sucht. Aus dieser Ãœberlegung folgt direkt, dass fÃ¼r einfache Probleme(z.B. $f(x,y) = x^2 + y^2$)(bei korrekter Parameterwahl) nach nur einem Schritt bereits eine LÃ¶sung gefunden wird.

\begin{figure}[t]
  \centering
  \includegraphics[width=.5\textwidth]{octave_contour_mod}
  \caption{Contourplot mit Visualisierung zu Schritt 2. Der rote Punkt zeigt die Startposition $x_k$, die blaue Linie einen Teil der durch $x_k + \alpha p_k$ beschriebenen Geraden. Durch eine eindimensionale Optimierung wird dann $\alpha_k$ so gewÃ¤hlt, dass man bei einem Minimum(orange/braune Ellipse) landet. Originalbild von \url{https://octave.sourceforge.io/octave/function/images/contour_101.png}.}
\end{figure}

In Schritt 2 wird die Ableitung von $f(x_k + \alpha p_k)$ nach $\alpha$ benÃ¶tigt - um diese nicht immer bestimmen zu mÃ¼ssen, werden wir sie einfach numerisch nÃ¤hern. Die Funktion \mintinline{Julia}|numeric_differentiation(f, h) = x -> (f(x + h) - f(x - h)) / (2 * h)| bestimmt mittels des zentralen Differenzquotienten die Ableitung einer eindimensionalen Funktion $f$.

Zum line search wÃ¤hlen wir zu Demozwecken den bereits bekannten Gradientenabstieg - diesmal jedoch in allgemeiner AusfÃ¼hrung und ohne Regularisierung etc..

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """Optimize some function f
    # Args:
        âˆ‡f: Gradient of f
        x_0: Initial guess
        Î·: learning rate
        Îµ: cancellation tolerance
        max_iters: maximum number of iterations
    """
    function gradient_descent(âˆ‡f::Function,
      x_0,
      Î·::Number,
      Îµ::Number,
      max_iters::Integer)
        x_k = x_0
        count = 0
        for _ = 1:max_iters
            if any(isnan.(x_k))
                error("Encoutered NaN")
            end
            if any(isinf.(x_k))
                error("Encoutered Inf")
            end
            count += 1
            p_k = -âˆ‡f(x_k)
            if norm(âˆ‡f(p_k)) < Îµ
                break
            end
            x_k += Î· * p_k
        end
        x_k
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|gradient_descent|}
  \label{listing:decay}
\end{listing}


Die liniensuchfunktionsagnostische Implementierung des BFGS-Algorithmus ist dann wie folgt:

\begin{listing}[H]
  \begin{minted}[bgcolor=bg]{Julia}
    """BFGS Optimization Algorithm

    # Args:
        âˆ‡f: Gradient of function to optimize
        x_0: Initial guess for optimal value
        iters: Maximum number of iterations before cancellation
        line_search: Line search function that's used
        Îµ: Optimization stops once the norm of the gradient is below this value
    """
    function BFGS(
      f::Function,
      âˆ‡f::Function, 
      x_0::Vector{<:Number}, 
      iters::Integer,
      line_search::Function,
      Îµ = 10e-12::Real)
        n = size(x_0)[1]
        x_k = x_0
        B_k = Matrix{typeof(x_0[1])}(I, n, n)

        for i = 1:iters
            if norm(âˆ‡f(x_k)) < Îµ
                break
            end
            # Step 1: obtain direction p_k by solving
            # B_k âˆ™ p_k = - (gradient of f at x_k)
            p_k = B_k \ -âˆ‡f(x_k)
            # Step 2.: Find stepsize Î±_k such that
            # Î±_k = arg min âˆ‚f(x_k + Î±_k * p_k)/âˆ‚Î±
            Î±_k = line_search(numeric_differentiation(Î±->(f(x_k + Î± * p_k)), 10e-10))
            # Step 3.
            s_k = Î±_k * p_k
            x_k_prime = x_k + s_k
            # Step 4.
            y_k = âˆ‡f(x_k_prime) - âˆ‡f(x_k)
            # Step 5.
            B_k += (y_k * y_k') / (y_k' * s_k) +
              - (B_k * s_k * s_k' * B_k) / (s_k' * B_k * s_k)
            x_k = x_k_prime
        end
        x_k
    end
  \end{minted}
  \caption{Funktion \mintinline{julia}|BFGS|}
  \label{listing:decay}
\end{listing}

Betrachten wir nun beispielsweise die Funktion $f(x) = \frac{x^5}{5000} + \frac{21 x^4}{4000} + \frac{17 x^3}{375} + \frac{293 x^2}{1000} + \frac{521 x}{1000}$ mit $\nabla f(x) = \frac{x^4}{1000} + \frac{21x^3}{1000} + \frac{17 x^2}{125} + \frac{293 x}{500} + \frac{521}{1000}$ und fÃ¼hren mit ihr BFGS aus
\mintinline{Julia}|BFGS(f, âˆ‡f, [0], 500, âˆ‡f -> gradient_descent(âˆ‡f, 10e-10, 1, 1e-10, 1000), 10e-5)|,
erhalten wir nach zwei Iterationen ein lokales Minimum bei $x=-1.1408$.

Eine recht simple Optimierung der Implementierung ist in Schritt 1 mÃ¶glich. Hier wird aktuell der \mintinline{Julia}|\|-Operator\footnote{\url{https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/}} eingesetzt. Dies ist zwar eine valide LÃ¶sung, jedoch nicht besonders effizient. Stattdessen kann hier nach \cite{wiki:BFGS} die Shermanâ€“Morrisonâ€“Woodbury Formel angewandt werden um die Inverse rekursiv zu beschreiben. Die Rekursionsvorschrift lautet:
$$
B_{k+1}^{-1} = B_k^{-1} + \frac{(\mathbf{s}_k^T \mathbf{y}_k + \mathbf{y}_k^T B_k^{-1} \mathbf{y}_k)(\mathbf{s}_k \mathbf{s}_k^T)}{(\mathbf{s}_k^T \mathbf{y}_k)^2} - \frac{B_k^{-1} \mathbf{y}_k \mathbf{s}_k^T + \mathbf{s}_k \mathbf{y}_k^T B_k^{-1}}{\mathbf{s}_k^T \mathbf{y}_k}.
$$
FÃ¼r die erste Iteration gilt $B_1 = I_n$, und daher auch $p_1 = -\nabla f(\mathbf{x}_k)$ bzw. $B_1^{-1} = I_n$.

Mit dem fertigen BFGS kann man nun \mintinline{Julia}|fit_linear_model| dahingehend erweitern/Ã¤ndern, dass es intern BFGS nutzt. AuÃŸerdem Ã¶ffnet BFGS die TÃ¼r zu anderen Verfahren wie z.B. logistischer Regression.

\newpage

\appendix

\section{Performancemessung}\label{appendix:measure}

Das Laufzeitverhalten wurde mittels des built-in Macros \mintinline{julia}|@time| gemessen. Testsystem war ein Intel i7-4790k@3.8GHz unter Linux Mint 19. Auswertung der Ausgabe des Macros erfolgte mittels des Python Scripts in Listing \ref{listing:measure}. Die Tabellenwerte ergeben sich als arithmetisches Mittel von 100 Aufrufen der Funktion \mintinline{julia}|fit_linear_model|.

\begin{listing}[H]
  \begin{minted}[bgcolor=bg, linenos]{Python}
    from statistics import mean
    import re
    
    """Regex to capture different components
    Examples:
      0.000103 seconds (818 allocations: 87.328 KiB)
      0.000388 seconds (3.78 k allocations: 412.406 KiB)
      0.598357 seconds (2.02 M allocations: 102.555 MiB, 3.13% gc time)
    """
    RE = r"\s*(?P<time>\d+\.\d*) seconds \((?:(?P<allocs>\d+(?:\.\d*)?)"\
        r"(?: (?P<allocsuffix>M|k))?) allocations: (?:(?P<mem>\d+\.\d*)"\
        r"(?: (?P<memsuffix>(?:KiB|MiB)))?)(?:, (?P<gctime>\d+\.\d*)% gc time)?\)"
    
    MEMORY_FACTOR = {None: 1, "MiB": 1, "KiB": 1 / 1024}
    

    def get_and_parse():
        try:
            while line := input():
                match = re.match(RE, line)
                time = float(match["time"])
                mem = float(match["mem"]) * MEMORY_FACTOR[match["memsuffix"]]
                if (gc_time:=match["gctime"]) is not None:
                    gc = float(gc_time)
                else:
                    gc = None
                yield (time, mem, gc)
        except EOFError: return None
    

    time, memory, gc_time = zip(*(x for x in get_and_parse()))
    gc_time = list(filter(lambda x: x is not None, gc_time))
    print(
        f"Time: {mean(time):.5f} s, RAM: {mean(memory):.3f} MiB, "\
        f"GC-time: {mean(gc_time):.2f} % (got {len(gc_time)} gc values)")

  \end{minted}
  \caption{Python Script zur \mintinline{julia}|@time| Auswertung}
  \label{listing:measure}
\end{listing}
Das Script wurde fÃ¼r Python 3.8.0 geschrieben und ist auch nicht in Ã¤lteren Versionen lauffÃ¤hig(hierzu mÃ¼sste man die Assignment Expressions ersetzen). Der Code gestaltet sich etwas komplizierter, da \mintinline{Julia}|@time| je nach Anzahl der Allokationen ein verschiedenes Ausgabeformat wÃ¤hlt. Daher seien spezielle Sprachfeatures und nicht-triviale Codepassagen hier kurz erlÃ¤utert:

Hintereinanderstehende Strings werden in Python automatisch verkettet - \texttt{\textbackslash} erlaubt es lange Zeilen umzubrechen. Der \mintinline{Python}|:=| Operator fÃ¼hrt eine \emph{Assignment Expression}\footnote{\url{https://www.python.org/dev/peps/pep-0572/}} aus. Diese funktionieren Ã¤hnlich einer Zuweisung in C oder auch ALGOL 68; in Kombination mit \mintinline{Python}|while| ergibt sich ein Konstrukt Ã¤hnlich einem \mintinline{Rust}|while let Some(x) = ...| in Rust. Die Funktion \mintinline{Python}|get_and_parse| fungiert als Generator\footnote{\url{https://docs.python.org/3/howto/functional.html}} welcher Ã¼ber stdin die Messwerte einliest, parset und als Dreiertupel zurÃ¼ckgibt. FÃ¼r eine zweidimensionale Collection \texttt{c} in row-major order wandelt \mintinline{Python}|zip(*c)| diese in eine in column-major order um. Bei \texttt{RE} handelt es sich um eine Regular Expression\footnote{\url{https://docs.python.org/3/library/re.html}} welche in diesem Fall alle Eingabeformate unterscheiden und die einzelnen Komponenten automatisch extrahieren kann. Bei \mintinline{Python}|(x for x in get_and_parse())| in Zeile \texttt{31} handelt es sich um eine \emph{Generator Expression}\footnote{\url{https://www.python.org/dev/peps/pep-0289/}} welche Ã¤hnlich zu einer List Comprehension in Python, Haskell, Erlang oder auch Julia funktioniert - jedoch im Effekt eine Art Lazy Evaluation realisiert. Diese Generator Expression wird hier nur benÃ¶tigt um das Entpacken mittels \texttt{*} zu ermÃ¶glichen. Die Konvertierung des Generators zu einer Liste in Zeile 32 ist leider nÃ¶tig (sofern man keine eigene Funktion schreibt, welche gleichzeitig die LÃ¤nge bestimmt und das Mittel berechnet) da der Generator beim Aufruf von \mintinline{Python}|len| oder \mintinline{Python}|mean| sonst verbraucht wÃ¼rde.
Die Nutzung erfolgt dann beispielsweise mit \mintinline{Bash}{$ julia Tests.jl | python3.8 measure.py}.

\bibliographystyle{alphadin}
\bibliography{Quellen}

\end{document}